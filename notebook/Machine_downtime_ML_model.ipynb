{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine Learning Model Development"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Import the necessary libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold, StratifiedShuffleSplit,\\\n",
    "                                    cross_val_predict\n",
    "from sklearn.preprocessing import RobustScaler, StandardScaler, LabelEncoder, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import accuracy_score, precision_score,\\\n",
    "                            recall_score, f1_score, roc_auc_score\n",
    "                            \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from optuna.visualization import plot_param_importances\n",
    "\n",
    "        \n",
    "\n",
    "import optuna"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Some useful Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_feature_importance(model, model_name):\n",
    "    \"\"\"\n",
    "    Extracts and plots feature importance for a trained model.\n",
    "\n",
    "    Parameters:\n",
    "    - model: Trained Pipeline containing the classifier.\n",
    "    - model_name: Name of the model ('Gradient Boosting' or 'XGBoost').\n",
    "    \"\"\"\n",
    "    # Extract classifier from pipeline\n",
    "    classifier = model.named_steps['classifier']\n",
    "    \n",
    "    # Get feature importance values\n",
    "    importance = classifier.feature_importances_\n",
    "    \n",
    "    # Get transformed feature names from the preprocessor\n",
    "    preprocessor = model.named_steps['preprocessor']\n",
    "    \n",
    "    try:\n",
    "        feature_names = preprocessor.get_feature_names_out()\n",
    "    except AttributeError:\n",
    "        feature_names = X_train.columns  # Fallback if `get_feature_names_out` is not available\n",
    "    \n",
    "    # Ensure feature_names and importance lengths match\n",
    "    if len(importance) != len(feature_names):\n",
    "        print(f\"Warning: Mismatch in feature importance length! ({len(importance)} vs {len(feature_names)})\")\n",
    "        feature_names = [f\"Feature {i}\" for i in range(len(importance))]  # Assign generic names\n",
    "    \n",
    "    # Sort feature importance values\n",
    "    sorted_idx = np.argsort(importance)[::-1]\n",
    "    \n",
    "    # Plot feature importance\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.barh(np.array(feature_names)[sorted_idx], importance[sorted_idx])\n",
    "    plt.xlabel(\"Feature Importance\")\n",
    "    plt.ylabel(\"Features\")\n",
    "    plt.title(f\"{model_name} Feature Importance\")\n",
    "    plt.gca().invert_yaxis()\n",
    "    plt.show()\n",
    "    \n",
    "    # Return feature importance as a dictionary\n",
    "    return dict(zip(feature_names, importance))\n",
    "\n",
    "    # Return feature importance as a dictionary\n",
    "    return dict(zip(feature_names, importance))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_param_importances_(study_model):\n",
    "    '''\n",
    "    plot the importance of the most important hyperparameter\n",
    "    \n",
    "    study_model: optuna optimized and tuned model\n",
    "    model: str. The model of interest\n",
    "    '''\n",
    "    plotly_config = {\"staticPlot\": True}\n",
    "    fig = plot_param_importances(study_model)\n",
    "    fig.show(config=plotly_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the dataset\n",
    "machine = pd.read_csv(\"../data/machine_downtime_cleaned.csv\", parse_dates=['Date'])\n",
    "\n",
    "# make a copy of the data \n",
    "machine_ori = machine.copy()\n",
    "# print the first few rows\n",
    "machine.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing\n",
    "\n",
    "we have to divide the numeric columns into those that are skewed and those that are normal in order to be able to apply the necessary standardization or normalization to avoid bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create an empty list to store columns that are normally or\n",
    "# skewly distributed\n",
    "normal_cols = []\n",
    "skewed_cols = []\n",
    "\n",
    "# loop through the numerical features\n",
    "for col in machine_ori.select_dtypes(include=np.number):\n",
    "    skewness = machine_ori[col].skew()\n",
    "    kurtosis = machine_ori[col].kurt()\n",
    "\n",
    "    # set a threshold for kurtosis and skewness and then append the necessary features\n",
    "    if -0.2 <= skewness <= 0.3 and -0.2 <= kurtosis <= 0.2:  # Adjust thresholds as needed\n",
    "        normal_cols.append(col)\n",
    "        print(f\"{col}: Skewness = {skewness:.2f}, Kurtosis = {kurtosis:.2f} (Approximately Normal)\")\n",
    "    else:\n",
    "        skewed_cols.append(col)\n",
    "        print(f\"{col}: Skewness = {skewness:.2f}, Kurtosis = {kurtosis:.2f} (Not Normally Distributed)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Parameters Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define target and features\n",
    "X = machine_ori.drop(columns=[\"Downtime\", \"Date\", \"Assembly_Line_No\"])  # Features\n",
    "\n",
    "# define encoder\n",
    "label_encode = LabelEncoder()\n",
    "y = label_encode.fit_transform(machine_ori[\"Downtime\"])  # Target variable\n",
    "\n",
    "# Identify numerical and categorical columns\n",
    "numerical_cols = X.select_dtypes(include=['float64', 'int64']).columns\n",
    "category_col = X.select_dtypes(include=['object']).columns\n",
    "\n",
    "# Define transformers\n",
    "preprocessor = ColumnTransformer([\n",
    "    (\"robust\", RobustScaler(), skewed_cols),  # Skewed data\n",
    "    (\"standard\", StandardScaler(), normal_cols),  # Normal data \n",
    "    ('one-hot-encoder', OneHotEncoder(), category_col) # Machine_ID column\n",
    "])\n",
    "\n",
    "# Train-test split\n",
    "# Step 1: Split into Train (60%), Validation (20%), Test (20%)\n",
    "X_train_val, X_test, y_train_val, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train_val, y_train_val, test_size=0.25, stratify=y_train_val, random_state=42)\n",
    "\n",
    "# Define models\n",
    "models = {\n",
    "    \"Bayesian Logistic Regression\": LogisticRegression(solver=\"lbfgs\"),\n",
    "    \"Random Forest\": RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "    \"Gradient Boosting\": GradientBoostingClassifier(n_estimators=100, random_state=42),\n",
    "    \"Decision Tree\": DecisionTreeClassifier(random_state=42),\n",
    "    \"SVM\": SVC(kernel=\"rbf\", probability=True, random_state=42),\n",
    "    \"XGBoost\": xgb.XGBClassifier(eval_metric=\"auc\", random_state = 42)\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the model \n",
    "#### Cross Validation\n",
    "\n",
    "Since our problem is a classification task, Stratified K-Fold (StratifiedKFold) will be use for the cross validation. \n",
    "\n",
    "Why Use Stratified K-Fold?\n",
    "\n",
    "+ Preserves Class Distribution: Stratified K-Fold ensures that each fold maintains the same proportion of classes as the overall dataset, which is crucial when dealing with classification problems, even if there is no visible class imbalance.\n",
    "+ More Reliable Performance Estimates: It provides a more stable and representative estimate of your model’s performance compared to ShuffleSplit, which may produce folds with different class distributions.\n",
    "+ Better Generalization: Ensures that all classes are well represented in training and validation splits, reducing the risk of biased results.\n",
    "\n",
    "**Key Performance Metrics and Their Meaning**\n",
    "\n",
    "+ Precision: Measures how many of the predicted failures were actually failures. A high precision means fewer false positives.\n",
    "+ Recall: Measures how many of the actual failures were correctly identified. A high recall means fewer false negatives.\n",
    "+ F1-Score: Harmonic mean of precision and recall, balancing both. Higher is better.\n",
    "+ ROC AUC: Measures the model’s ability to distinguish between classes. A value closer to 1 is better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# craete an empty list to store model result\n",
    "model_results = []\n",
    "\n",
    "# Initialize Stratified K-Fold\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "for name, model in models.items():\n",
    "    precision_scores, recall_scores, f1_scores, roc_auc_scores = [], [], [], []\n",
    "\n",
    "    for train_index, val_index in cv.split(X_train_val, y_train_val):\n",
    "        X_train_fold, X_val_fold = X_train_val.iloc[train_index], X_train_val.iloc[val_index]\n",
    "        y_train_fold, y_val_fold = y_train_val[train_index], y_train_val[val_index]\n",
    "\n",
    "        # Create a pipeline\n",
    "        pipeline = Pipeline([\n",
    "            ('preprocessor', preprocessor),\n",
    "            ('classifier', model)\n",
    "        ])\n",
    "\n",
    "        # Train the model\n",
    "        pipeline.fit(X_train_fold, y_train_fold)\n",
    "\n",
    "        # Make predictions\n",
    "        y_pred = pipeline.predict(X_val_fold)\n",
    "        y_prob = pipeline.predict_proba(X_val_fold)[:, 1] if hasattr(model, 'predict_proba') else None\n",
    "\n",
    "        # Evaluate Metrics\n",
    "        precision_scores.append(precision_score(y_val_fold, y_pred))\n",
    "        recall_scores.append(recall_score(y_val_fold, y_pred))\n",
    "        f1_scores.append(f1_score(y_val_fold, y_pred))\n",
    "        roc_auc_scores.append(roc_auc_score(y_val_fold, y_prob) if y_prob is not None else np.nan)\n",
    "\n",
    "    # Compute mean scores across folds\n",
    "    mean_precision = np.mean(precision_scores)\n",
    "    mean_recall = np.mean(recall_scores)\n",
    "    mean_f1 = np.mean(f1_scores)\n",
    "    mean_roc_auc = np.nanmean(roc_auc_scores)\n",
    "\n",
    "    # Append results\n",
    "    model_results.append({\n",
    "        \"Model\": name,\n",
    "        \"Precision\": round(mean_precision, 4),\n",
    "        \"Recall\": round(mean_recall, 4),\n",
    "        \"F1-Score\": round(mean_f1, 4),\n",
    "        \"ROC AUC\": round(mean_roc_auc, 4)\n",
    "    })\n",
    "\n",
    "\n",
    "# Convert results to DataFrame\n",
    "model_results_df = pd.DataFrame(model_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Performance and Best Result\n",
    "\n",
    "**Model Performance Interpretation**\n",
    "\n",
    "1. XGBoost (0.9993 ROC AUC, 0.9919 F1-Score)\n",
    "> + Remains a top performer with exceptional discrimination ability (ROC AUC) and a near-perfect balance of precision and recall (F1-Score).\n",
    "> + It's likely to generalize well to the test set.\n",
    "\n",
    "2. Random Forest (0.9990 ROC AUC, 0.9858 F1-Score)\n",
    "> + Also demonstrates excellent performance, very close to XGBoost.\n",
    "> + If interpretability is crucial, it might be preferable.\n",
    "\n",
    "3. Gradient Boosting (0.9991 ROC AUC, 0.9919 F1-Score)\n",
    "> + Achieves top-tier performance, comparable to XGBoost, with a slight edge in recall.\n",
    "\n",
    "4. Decision Tree (0.9694 ROC AUC, 0.9692 F1-Score)\n",
    "> + Shows good performance but falls short compared to the ensemble methods (XGBoost, Random Forest, Gradient Boosting).\n",
    "\n",
    "5. SVM (0.9439 ROC AUC, 0.8779 F1-Score)\n",
    "> + Exhibits decent performance but is outperformed by the ensemble models.\n",
    "\n",
    "6. Bayesian Logistic Regression (0.9292 ROC AUC, 0.8625 F1-Score)\n",
    "> + Shows moderate performance, lagging behind the other models.\n",
    "\n",
    "**Observations**\n",
    "> + Ensemble methods (XGBoost, Random Forest, Gradient Boosting) consistently outperform the single models (Decision Tree, SVM, Bayesian Logistic Regression).\n",
    "> + XGBoost, Random Forest, and Gradient Boosting have shown remarkable performance, with very high ROC AUC and F1-Scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_results_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter Tuning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross-validation function\n",
    "def cross_validate_model(model):\n",
    "    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    f1_scores, precision_scores, recall_scores, roc_auc_scores = [], [], [], []\n",
    "    \n",
    "    for train_idx, val_idx in skf.split(X_train, y_train):\n",
    "        X_train_fold, X_val_fold = X_train.iloc[train_idx], X_train.iloc[val_idx]\n",
    "        y_train_fold, y_val_fold = y_train[train_idx], y_train[val_idx]\n",
    "        \n",
    "        pipeline = Pipeline([\n",
    "            ('preprocessor', preprocessor),\n",
    "            ('classifier', model)\n",
    "        ])\n",
    "        \n",
    "        pipeline.fit(X_train_fold, y_train_fold)\n",
    "        y_pred = pipeline.predict(X_val_fold)\n",
    "        y_prob = pipeline.predict_proba(X_val_fold)[:, 1] if hasattr(model, 'predict_proba') else None\n",
    "        \n",
    "        f1_scores.append(f1_score(y_val_fold, y_pred))\n",
    "        precision_scores.append(precision_score(y_val_fold, y_pred))\n",
    "        recall_scores.append(recall_score(y_val_fold, y_pred))\n",
    "        roc_auc_scores.append(roc_auc_score(y_val_fold, y_prob))\n",
    "    \n",
    "    return np.mean([np.mean(f1_scores), np.mean(precision_scores), np.mean(recall_scores), np.mean(roc_auc_scores)])\n",
    "\n",
    "# Define Optuna objective functions for each model\n",
    "def objective_xgb(trial):\n",
    "    params = {\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 100, 500, step=50),\n",
    "        'max_depth': trial.suggest_int('max_depth', 3, 12),\n",
    "        'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
    "        'subsample': trial.suggest_float('subsample', 0.6, 1.0),\n",
    "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.6, 1.0),\n",
    "        'gamma': trial.suggest_float('gamma', 0, 10),\n",
    "        'reg_alpha': trial.suggest_float('reg_alpha', 0, 10),\n",
    "        'reg_lambda': trial.suggest_float('reg_lambda', 0, 10),\n",
    "        'random_state': 42,\n",
    "       # 'use_label_encoder': False,\n",
    "        'eval_metric': 'auc'\n",
    "    }\n",
    "    return cross_validate_model(xgb.XGBClassifier(**params))\n",
    "\n",
    "\n",
    "def objective_gb(trial):\n",
    "    params = {\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 100, 500, step=50),\n",
    "        'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
    "        'max_depth': trial.suggest_int('max_depth', 3, 12),\n",
    "        'subsample': trial.suggest_float('subsample', 0.6, 1.0),\n",
    "        'random_state': 42\n",
    "    }\n",
    "    return cross_validate_model(GradientBoostingClassifier(**params))\n",
    "\n",
    "\n",
    "\n",
    "# Run Optuna for each model\n",
    "study_xgb = optuna.create_study(direction='maximize')\n",
    "study_xgb.optimize(objective_xgb, n_trials=50, timeout=1800)\n",
    "\n",
    "study_gb = optuna.create_study(direction='maximize')\n",
    "study_gb.optimize(objective_gb, n_trials=50, timeout=1800)\n",
    "\n",
    "# Train best models\n",
    "best_gb = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', GradientBoostingClassifier(**study_gb.best_params, random_state=42))\n",
    "])\n",
    "best_gb.fit(X_train, y_train)\n",
    "\n",
    "best_xgb = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', xgb.XGBClassifier(**study_xgb.best_params, random_state=42, eval_metric='auc'))\n",
    "])\n",
    "best_xgb.fit(X_train, y_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get the best parameters for each model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the best hyperparameters for the gradient boost\n",
    "print(\"Gradient Boost Best params:\")\n",
    "for key, value in study_gb.best_params.items():\n",
    "    print(f\"\\t{key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the best hyperparameters for the XG Boost\n",
    "print(\"XGBoost Best params:\")\n",
    "for key, value in study_xgb.best_params.items():\n",
    "    print(f\"\\t{key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate model on the Test set\n",
    "\n",
    "#### Interpretation of Test Set Results\n",
    "\n",
    "1. XGBoost (0.9991 ROC AUC, 0.9816 F1-Score)\n",
    "+ Maintains excellent performance on the test set, with a very high ROC AUC and F1-Score.\n",
    "+ This indicates strong generalization ability, meaning it's likely to perform well on new, unseen data.\n",
    "\n",
    "2. Gradient Boosting (0.9989 ROC AUC, 0.9857 F1-Score)\n",
    "+ Also shows outstanding performance on the test set, comparable to XGBoost.\n",
    "+ Achieves a slightly higher F1-Score than XGBoost, indicating a marginally better balance of precision and recall.\n",
    "\n",
    "3. Random Forest (0.9989 ROC AUC, 0.9837 F1-Score)\n",
    "+ Performs very well on the test set, with a high ROC AUC and F1-Score.\n",
    "+ While slightly behind XGBoost and Gradient Boosting, it's still a strong model.\n",
    "\n",
    "**Observations**\n",
    "\n",
    "All three models generalize well to the test set, confirming their strong performance observed during training and validation.\n",
    "Gradient Boosting has a slight edge in F1-Score on the test set, suggesting a better balance of precision and recall compared to XGBoost.\n",
    "The performance differences between the models are relatively small, indicating that all three are good candidates for deployment.\n",
    "\n",
    "**Recommendations**\n",
    "\n",
    "Model Selection:\n",
    "\n",
    "Our primary focus in selecting a predictive model is maximizing accuracy in identifying potential machine downtime. While computational efficiency and interpretability are valuable,  the ability to proactively prevent downtime is paramount.\n",
    "\n",
    "In this regard, Gradient Boosting emerged as the top performer, achieving the highest F1-score among the models evaluated. This signifies its superior balance between precision (minimizing false alarms) and recall (capturing the majority of actual downtime events).\n",
    "\n",
    "Therefore, we will be deploying Gradient Boosting as our predictive model to proactively mitigate machine downtime and enhance operational efficiency.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate on test set\n",
    "def evaluate_model(model, name):\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_prob = model.predict_proba(X_test)[:, 1] if hasattr(model, 'predict_proba') else None\n",
    "    return {\n",
    "        'Model': name,\n",
    "        'Precision': round(precision_score(y_test, y_pred), 4),\n",
    "        'Recall': round(recall_score(y_test, y_pred), 4),\n",
    "        'F1-Score': round(f1_score(y_test, y_pred), 4),\n",
    "        'ROC AUC': round(roc_auc_score(y_test, y_prob) , 4) if y_prob is not None else 'N/A'\n",
    "    }\n",
    "\n",
    "results = [\n",
    "    evaluate_model(best_xgb, 'XGBoost'),\n",
    "    evaluate_model(best_gb, 'Gradient Boosting')\n",
    "]\n",
    "\n",
    "import pandas as pd\n",
    "results_df = pd.DataFrame(results).sort_values(by=[])\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot Feature Importance After evaluating on test set\n",
    "\n",
    "#### 1. Key Takeaways from the Plots\n",
    "\n",
    "**Top Features:**\n",
    "\n",
    "Both models strongly prioritize Hydraulic Pressure (Pa), Torque (Nm), and Cutting (N) as the most influential factors.\n",
    "This suggests that variations in these parameters significantly impact machine failures.\n",
    "\n",
    "**Coolant Pressure and Temperature:**\n",
    "\n",
    "> Features related to coolant pressure and temperature also have noticeable importance, indicating that overheating or coolant system inefficiencies might lead to failures.\n",
    "\n",
    "**Spindle Speed and Vibration:**\n",
    "\n",
    "> Spindle Speed (RPS), Tool Vibration, and Spindle Vibration appear as moderately important features.\n",
    "> This aligns with the mechanical behavior of precision machining—irregular spindle movement or excessive vibration can indicate wear and tear.\n",
    "Machine ID Encoding:\n",
    "\n",
    "> The one-hot encoded Machine_ID features have the lowest importance: This suggests that machine-specific factors are not as crucial as operational parameters (e.g., pressure, torque, cutting force).\n",
    "\n",
    "##### 2. XGBoost vs. Gradient Boosting Comparison\n",
    "\n",
    "**XGBoost:**\n",
    "\n",
    "+ Hydraulic Pressure (Pa) dominates with the highest importance (~0.35).\n",
    "+ More balanced importance distribution across features.\n",
    "+ Slightly higher weight for Torque (Nm) and Cutting (N) compared to other features.\n",
    "\n",
    "**Gradient Boosting:**\n",
    "\n",
    "+ Hydraulic Pressure (Pa) is even more dominant (~0.42).\n",
    "+ Less variation in importance among the remaining features, meaning it relies more on a few strong predictors.\n",
    "+ Coolant Temperature and Vibration features contribute less compared to XGBoost.\n",
    "\n",
    "#### 3. Summary of the Analysis\n",
    "\n",
    "> + Hydraulic Pressure (Pa), Torque (Nm), and Cutting (N) are the strongest predictors of machine downtime. If these parameters exceed a threshold, the likelihood of failure increases.\n",
    "> + Coolant and spindle-related factors play a secondary role, suggesting that temperature regulation and machine stability (vibration) contribute to faults.\n",
    "> + Machine ID has minimal impact, implying that failures are more dependent on operational conditions than the specific machine being used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get feature importance for the optimized Gradient Boosting model\n",
    "gb_feature_importance = get_feature_importance(best_gb, \"Gradient Boosting\")\n",
    "\n",
    "# Get feature importance for the optimized XGBoost model\n",
    "xgb_feature_importance = get_feature_importance(best_xgb, \"XGBoost\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot Hyperparameter Importance\n",
    "\n",
    "Visualize how much each hyperparameter contributes to model performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot of Gradient boost most hyperparameter importance\n",
    "plot_param_importances_(study_gb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot XGBoost  hyperparameter importance\n",
    "plot_param_importances_(study_xgb)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
