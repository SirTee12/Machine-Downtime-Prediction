{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine Learning Model Development"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Import the necessary libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Administrator\\anaconda3\\envs\\machineind\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold, StratifiedShuffleSplit\n",
    "from sklearn.preprocessing import RobustScaler, StandardScaler, LabelEncoder, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import accuracy_score, precision_score,\\\n",
    "                            recall_score, f1_score, roc_auc_score\n",
    "        \n",
    "\n",
    "import optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Machine_ID</th>\n",
       "      <th>Assembly_Line_No</th>\n",
       "      <th>Coolant_Temperature</th>\n",
       "      <th>Hydraulic_Oil_Temperature</th>\n",
       "      <th>Spindle_Bearing_Temperature</th>\n",
       "      <th>Spindle_Vibration</th>\n",
       "      <th>Tool_Vibration</th>\n",
       "      <th>Voltage(volts)</th>\n",
       "      <th>Torque(Nm)</th>\n",
       "      <th>Downtime</th>\n",
       "      <th>Hydraulic_Pressure(Pa)</th>\n",
       "      <th>Coolant_Pressure(Pa)</th>\n",
       "      <th>Air_System_Pressure(Pa)</th>\n",
       "      <th>Cutting(N)</th>\n",
       "      <th>Spindle_Speed(RPS)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-12-08</td>\n",
       "      <td>Makino-L2-Unit1-2015</td>\n",
       "      <td>Shopfloor-L2</td>\n",
       "      <td>4.5</td>\n",
       "      <td>47.9</td>\n",
       "      <td>31.2</td>\n",
       "      <td>1.225</td>\n",
       "      <td>35.214</td>\n",
       "      <td>381.0</td>\n",
       "      <td>23.091903</td>\n",
       "      <td>No_Machine_Failure</td>\n",
       "      <td>14115919.3</td>\n",
       "      <td>513860.1</td>\n",
       "      <td>612765.0</td>\n",
       "      <td>2870.0</td>\n",
       "      <td>253.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-12-17</td>\n",
       "      <td>Makino-L2-Unit1-2015</td>\n",
       "      <td>Shopfloor-L2</td>\n",
       "      <td>21.7</td>\n",
       "      <td>47.5</td>\n",
       "      <td>35.8</td>\n",
       "      <td>1.078</td>\n",
       "      <td>29.198</td>\n",
       "      <td>367.0</td>\n",
       "      <td>31.620335</td>\n",
       "      <td>No_Machine_Failure</td>\n",
       "      <td>7246602.0</td>\n",
       "      <td>514111.3</td>\n",
       "      <td>662932.2</td>\n",
       "      <td>2970.0</td>\n",
       "      <td>295.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-12-17</td>\n",
       "      <td>Makino-L1-Unit1-2013</td>\n",
       "      <td>Shopfloor-L1</td>\n",
       "      <td>5.2</td>\n",
       "      <td>49.4</td>\n",
       "      <td>34.2</td>\n",
       "      <td>1.266</td>\n",
       "      <td>30.206</td>\n",
       "      <td>340.0</td>\n",
       "      <td>15.900716</td>\n",
       "      <td>Machine_Failure</td>\n",
       "      <td>8828000.0</td>\n",
       "      <td>683941.3</td>\n",
       "      <td>656038.1</td>\n",
       "      <td>2700.0</td>\n",
       "      <td>466.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-12-17</td>\n",
       "      <td>Makino-L1-Unit1-2013</td>\n",
       "      <td>Shopfloor-L1</td>\n",
       "      <td>24.4</td>\n",
       "      <td>48.1</td>\n",
       "      <td>36.6</td>\n",
       "      <td>0.778</td>\n",
       "      <td>25.048</td>\n",
       "      <td>307.0</td>\n",
       "      <td>23.923929</td>\n",
       "      <td>Machine_Failure</td>\n",
       "      <td>7454000.0</td>\n",
       "      <td>658019.5</td>\n",
       "      <td>652883.7</td>\n",
       "      <td>3590.0</td>\n",
       "      <td>466.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-12-21</td>\n",
       "      <td>Makino-L2-Unit1-2015</td>\n",
       "      <td>Shopfloor-L2</td>\n",
       "      <td>14.1</td>\n",
       "      <td>51.8</td>\n",
       "      <td>32.4</td>\n",
       "      <td>0.969</td>\n",
       "      <td>31.491</td>\n",
       "      <td>380.0</td>\n",
       "      <td>16.964105</td>\n",
       "      <td>Machine_Failure</td>\n",
       "      <td>5326000.0</td>\n",
       "      <td>683941.3</td>\n",
       "      <td>602069.0</td>\n",
       "      <td>2860.0</td>\n",
       "      <td>460.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Date            Machine_ID Assembly_Line_No  Coolant_Temperature  \\\n",
       "0 2021-12-08  Makino-L2-Unit1-2015     Shopfloor-L2                  4.5   \n",
       "1 2021-12-17  Makino-L2-Unit1-2015     Shopfloor-L2                 21.7   \n",
       "2 2021-12-17  Makino-L1-Unit1-2013     Shopfloor-L1                  5.2   \n",
       "3 2021-12-17  Makino-L1-Unit1-2013     Shopfloor-L1                 24.4   \n",
       "4 2021-12-21  Makino-L2-Unit1-2015     Shopfloor-L2                 14.1   \n",
       "\n",
       "   Hydraulic_Oil_Temperature  Spindle_Bearing_Temperature  Spindle_Vibration  \\\n",
       "0                       47.9                         31.2              1.225   \n",
       "1                       47.5                         35.8              1.078   \n",
       "2                       49.4                         34.2              1.266   \n",
       "3                       48.1                         36.6              0.778   \n",
       "4                       51.8                         32.4              0.969   \n",
       "\n",
       "   Tool_Vibration  Voltage(volts)  Torque(Nm)            Downtime  \\\n",
       "0          35.214           381.0   23.091903  No_Machine_Failure   \n",
       "1          29.198           367.0   31.620335  No_Machine_Failure   \n",
       "2          30.206           340.0   15.900716     Machine_Failure   \n",
       "3          25.048           307.0   23.923929     Machine_Failure   \n",
       "4          31.491           380.0   16.964105     Machine_Failure   \n",
       "\n",
       "   Hydraulic_Pressure(Pa)  Coolant_Pressure(Pa)  Air_System_Pressure(Pa)  \\\n",
       "0              14115919.3              513860.1                 612765.0   \n",
       "1               7246602.0              514111.3                 662932.2   \n",
       "2               8828000.0              683941.3                 656038.1   \n",
       "3               7454000.0              658019.5                 652883.7   \n",
       "4               5326000.0              683941.3                 602069.0   \n",
       "\n",
       "   Cutting(N)  Spindle_Speed(RPS)  \n",
       "0      2870.0               253.6  \n",
       "1      2970.0               295.4  \n",
       "2      2700.0               466.0  \n",
       "3      3590.0               466.0  \n",
       "4      2860.0               460.2  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the dataset\n",
    "machine = pd.read_csv(\"../data/machine_downtime_cleaned.csv\", parse_dates=['Date'])\n",
    "\n",
    "# make a copy of the data \n",
    "machine_ori = machine.copy()\n",
    "# print the first few rows\n",
    "machine.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing\n",
    "\n",
    "we have to divide the numeric columns into those that are skewed and those that are normal in order to be able to apply the necessary standardization or normalization to avoid bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coolant_Temperature: Skewness = -0.22, Kurtosis = -1.35 (Not Normally Distributed)\n",
      "Hydraulic_Oil_Temperature: Skewness = -0.00, Kurtosis = 0.05 (Approximately Normal)\n",
      "Spindle_Bearing_Temperature: Skewness = -0.03, Kurtosis = -0.05 (Approximately Normal)\n",
      "Spindle_Vibration: Skewness = 0.03, Kurtosis = -0.11 (Approximately Normal)\n",
      "Tool_Vibration: Skewness = -0.06, Kurtosis = 0.01 (Approximately Normal)\n",
      "Voltage(volts): Skewness = -0.03, Kurtosis = -0.09 (Approximately Normal)\n",
      "Torque(Nm): Skewness = 0.03, Kurtosis = -0.46 (Not Normally Distributed)\n",
      "Hydraulic_Pressure(Pa): Skewness = 0.21, Kurtosis = -0.98 (Not Normally Distributed)\n",
      "Coolant_Pressure(Pa): Skewness = -0.01, Kurtosis = -0.13 (Approximately Normal)\n",
      "Air_System_Pressure(Pa): Skewness = -0.05, Kurtosis = 0.01 (Approximately Normal)\n",
      "Cutting(N): Skewness = 0.12, Kurtosis = -1.09 (Not Normally Distributed)\n",
      "Spindle_Speed(RPS): Skewness = 0.22, Kurtosis = -0.45 (Not Normally Distributed)\n"
     ]
    }
   ],
   "source": [
    "# create an empty list to store columns that are normally or\n",
    "# skewly distributed\n",
    "normal_cols = []\n",
    "skewed_cols = []\n",
    "\n",
    "# loop through the numerical features\n",
    "for col in machine_ori.select_dtypes(include=np.number):\n",
    "    skewness = machine_ori[col].skew()\n",
    "    kurtosis = machine_ori[col].kurt()\n",
    "\n",
    "    # set a threshold for kurtosis and skewness and then append the necessary features\n",
    "    if -0.2 <= skewness <= 0.3 and -0.2 <= kurtosis <= 0.2:  # Adjust thresholds as needed\n",
    "        normal_cols.append(col)\n",
    "        print(f\"{col}: Skewness = {skewness:.2f}, Kurtosis = {kurtosis:.2f} (Approximately Normal)\")\n",
    "    else:\n",
    "        skewed_cols.append(col)\n",
    "        print(f\"{col}: Skewness = {skewness:.2f}, Kurtosis = {kurtosis:.2f} (Not Normally Distributed)\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Parameters Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define target and features\n",
    "X = machine_ori.drop(columns=[\"Downtime\", \"Machine_ID\", \"Date\", \"Assembly_Line_No\"])  # Features\n",
    "\n",
    "# define encoder\n",
    "label_encode = LabelEncoder()\n",
    "y = label_encode.fit_transform(machine_ori[\"Downtime\"])  # Target variable\n",
    "\n",
    "# Identify numerical and categorical columns\n",
    "numerical_cols = X.select_dtypes(include=['float64', 'int64']).columns\n",
    "\n",
    "# Define transformers\n",
    "preprocessor = ColumnTransformer([\n",
    "    (\"robust\", RobustScaler(), skewed_cols),  # Skewed data\n",
    "    (\"standard\", StandardScaler(), normal_cols)  # Normal data \n",
    "])\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25,\n",
    "                                                    stratify = y, random_state=42)\n",
    "\n",
    "# Define models\n",
    "models = {\n",
    "    \"Bayesian Logistic Regression\": LogisticRegression(solver=\"lbfgs\"),\n",
    "    \"Random Forest\": RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "    \"Gradient Boosting\": GradientBoostingClassifier(n_estimators=100, random_state=42),\n",
    "    \"Decision Tree\": DecisionTreeClassifier(random_state=42),\n",
    "    \"SVM\": SVC(kernel=\"rbf\", probability=True, random_state=42),\n",
    "    \"XGBoost\": xgb.XGBClassifier(use_label_encoder=False, eval_metric=\"logloss\", random_state = 42)\n",
    "}\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the model \n",
    "\n",
    "**Key Performance Metrics and Their Meaning**\n",
    "\n",
    "+ Precision: Measures how many of the predicted failures were actually failures. A high precision means fewer false positives.\n",
    "+ Recall: Measures how many of the actual failures were correctly identified. A high recall means fewer false negatives.\n",
    "+ F1-Score: Harmonic mean of precision and recall, balancing both. Higher is better.\n",
    "+ ROC AUC: Measures the model’s ability to distinguish between classes. A value closer to 1 is better.\n",
    "\n",
    "**Model Comparison and Best Performing Model**\n",
    "\n",
    "Model Performance Interpretation:\n",
    "\n",
    "1. Best Overall Model: XGBoost (0.9993 ROC AUC, 0.9869 F1-Score)\n",
    "\n",
    "+ Highest ROC AUC (0.9993) → Best discrimination ability.\n",
    "+ Very high precision (0.9934) → Almost all predicted failures were actual failures.\n",
    "+ Very high recall (0.9805) → Nearly all actual failures were correctly identified.\n",
    "+ Strong balance between precision & recall (F1-Score = 0.9869).\n",
    "\n",
    "Likely the best choice for deployment.\n",
    "\n",
    "2. Random Forest is also very strong (0.9989 ROC AUC, 0.9870 F1-Score)\n",
    "\n",
    "> + Very similar performance to XGBoost.\n",
    "> + If interpretability is needed, Random Forest may be preferable.\n",
    "\n",
    "3. Gradient Boosting also performs well (0.9981 ROC AUC, 0.9853 F1-Score)\n",
    "\n",
    "> + Close competitor but slightly lower recall than XGBoost.\n",
    "\n",
    "4. Decision Tree (0.9647 ROC AUC, 0.9644 F1-Score)\n",
    "\n",
    "Still good but lacks the power of ensemble methods.\n",
    "\n",
    "5. SVM & Bayesian Logistic Regression are weaker\n",
    "\n",
    "> + SVM (0.9469 ROC AUC, 0.8696 F1-Score) and Bayesian Logistic Regression (0.9125 ROC AUC, 0.8419 F1-Score) underperform compared to ensemble models.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Administrator\\anaconda3\\envs\\machineind\\lib\\site-packages\\xgboost\\core.py:158: UserWarning: [08:23:02] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "# craete an empty list to store model result\n",
    "model_results = []\n",
    "\n",
    "# iterate through the models\n",
    "for name, model in models.items():\n",
    "    # create a pipeline\n",
    "    pipeline = Pipeline([\n",
    "        \n",
    "        ('preprocessor', preprocessor),\n",
    "        ('classifier', model)\n",
    "        \n",
    "        ])\n",
    "    pipeline.fit(X_train, y_train)\n",
    "    y_pred = pipeline.predict(X_test)\n",
    "    y_prob = pipeline.predict_proba(X_test)[:, 1] if hasattr(model, 'predict_proba')\\\n",
    "             else None\n",
    "    \n",
    "    # evaluate Metrics\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    roc_auc = roc_auc_score(y_test, y_prob) if y_prob is not None else 'N/A'\n",
    "    \n",
    "    # append result\n",
    "    model_results.append({\n",
    "        \"Model\": name,\n",
    "        \"Precision\": round(precision, 4),\n",
    "        \"Recall\": round(recall, 4),\n",
    "        \"F1-Score\": round(f1, 4),\n",
    "        \"ROC AUC\": round(roc_auc, 4) if roc_auc != \"N/A\" else \"N/A\"\n",
    "    })\n",
    "    \n",
    "    # convert result to Datframe\n",
    "    model_results_df = pd.DataFrame(model_results)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1-Score</th>\n",
       "      <th>ROC AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bayesian Logistic Regression</td>\n",
       "      <td>0.8365</td>\n",
       "      <td>0.8474</td>\n",
       "      <td>0.8419</td>\n",
       "      <td>0.9125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.9870</td>\n",
       "      <td>0.9870</td>\n",
       "      <td>0.9870</td>\n",
       "      <td>0.9989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Gradient Boosting</td>\n",
       "      <td>0.9934</td>\n",
       "      <td>0.9773</td>\n",
       "      <td>0.9853</td>\n",
       "      <td>0.9981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.9613</td>\n",
       "      <td>0.9675</td>\n",
       "      <td>0.9644</td>\n",
       "      <td>0.9647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SVM</td>\n",
       "      <td>0.8626</td>\n",
       "      <td>0.8766</td>\n",
       "      <td>0.8696</td>\n",
       "      <td>0.9469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.9934</td>\n",
       "      <td>0.9805</td>\n",
       "      <td>0.9869</td>\n",
       "      <td>0.9993</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Model  Precision  Recall  F1-Score  ROC AUC\n",
       "0  Bayesian Logistic Regression     0.8365  0.8474    0.8419   0.9125\n",
       "1                 Random Forest     0.9870  0.9870    0.9870   0.9989\n",
       "2             Gradient Boosting     0.9934  0.9773    0.9853   0.9981\n",
       "3                 Decision Tree     0.9613  0.9675    0.9644   0.9647\n",
       "4                           SVM     0.8626  0.8766    0.8696   0.9469\n",
       "5                       XGBoost     0.9934  0.9805    0.9869   0.9993"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_results_df.head(10)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check for Class Imbalance\n",
    "\n",
    "I have trained all the models involved, and most of them exhibit exceptionally high evaluation metric values, reaching as high as 0.99. Given that this is a classification problem, one potential concern could be class imbalance, which often leads to inflated performance metrics. However, after thoroughly checking the class distribution, there doesn’t appear to be any significant imbalance. This suggests that the models might either be capturing strong patterns in the data or potentially overfitting. Further investigation, such as cross-validation performance consistency and feature importance analysis, may be necessary to ensure the models’ generalizability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Downtime\n",
       "Machine_Failure       1257\n",
       "No_Machine_Failure    1230\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "machine_ori['Downtime'].value_counts()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert X_train and y_train to Pandas DataFrames/Series if needed\n",
    "if isinstance(X_train, np.ndarray):\n",
    "    X_train = pd.DataFrame(X_train)\n",
    "if isinstance(y_train, np.ndarray):\n",
    "    y_train = pd.Series(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the objective function for Optuna\n",
    "def objective(trial):\n",
    "    params = {\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 100, 500, step=50),\n",
    "        'max_depth': trial.suggest_int('max_depth', 3, 12),\n",
    "        'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
    "        'subsample': trial.suggest_float('subsample', 0.6, 1.0),\n",
    "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.6, 1.0),\n",
    "        'gamma': trial.suggest_float('gamma', 0, 10),\n",
    "        'reg_alpha': trial.suggest_float('reg_alpha', 0, 10),\n",
    "        'reg_lambda': trial.suggest_float('reg_lambda', 0, 10),\n",
    "        'random_state': 42,\n",
    "        'use_label_encoder': False,\n",
    "        'eval_metric': 'auc'\n",
    "    }\n",
    "    \n",
    "    # instantiate the kfold\n",
    "    strat_kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    roc_auc_scores = []    # instatntiate an empty list to store the roc_auc scores\n",
    "\n",
    "    for train_index, val_index in strat_kfold.split(X_train, y_train):\n",
    "        X_train_fold, X_val_fold = X_train.iloc[train_index], X_train.iloc[train_index]\n",
    "        y_train_fold, y_val_fold = y_train.iloc[train_index], y_train.iloc[val_index]\n",
    "        # Ensure X_train and y_train are Pandas DataFrame/Series\n",
    "\n",
    "        #print(X_train_fold.shape, X_val_fold.shape, y_train_fold.shape, y_val_fold.shape)\n",
    "        y_train_fold = y_train_fold.values.ravel()\n",
    "        y_val_fold = y_val_fold.values.ravel()\n",
    "\n",
    "    \n",
    "        model = xgb.XGBClassifier(**params)\n",
    "        model.fit(X_train_fold, y_train_fold,\n",
    "                    eval_set = [(X_val_fold, y_val_fold)],\n",
    "                     verbose = False)\n",
    "        y_pred = model.predict_proba(X_val_fold)[:, 1]\n",
    "        roc_auc_scores.append(roc_auc_score(y_val_fold, y_pred))\n",
    "    return mean(roc_auc_scores)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-27 20:50:48,326] A new study created in memory with name: no-name-4e5f8afe-30d0-433a-ae09-2a5855e5942a\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_2452\\489361234.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
      "[W 2025-02-27 20:50:48,352] Trial 0 failed with parameters: {'n_estimators': 200, 'max_depth': 3, 'learning_rate': 0.23965282989838496, 'subsample': 0.7722967895638201, 'colsample_bytree': 0.6739608956964448, 'gamma': 6.805526372132293, 'reg_alpha': 2.2893470812400696, 'reg_lambda': 0.17018386825966347} because of the following error: XGBoostError('[20:50:48] C:\\\\buildkite-agent\\\\builds\\\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\\\xgboost\\\\xgboost-ci-windows\\\\src\\\\data\\\\data.cc:508: Check failed: this->labels.Size() % this->num_row_ == 0 (373 vs. 0) : Incorrect size for labels.').\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Administrator\\anaconda3\\envs\\machineind\\lib\\site-packages\\optuna\\study\\_optimize.py\", line 197, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_2452\\489361234.py\", line 32, in objective\n",
      "    model.fit(X_train_fold, y_train_fold,\n",
      "  File \"c:\\Users\\Administrator\\anaconda3\\envs\\machineind\\lib\\site-packages\\xgboost\\core.py\", line 726, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"c:\\Users\\Administrator\\anaconda3\\envs\\machineind\\lib\\site-packages\\xgboost\\sklearn.py\", line 1580, in fit\n",
      "    train_dmatrix, evals = _wrap_evaluation_matrices(\n",
      "  File \"c:\\Users\\Administrator\\anaconda3\\envs\\machineind\\lib\\site-packages\\xgboost\\sklearn.py\", line 654, in _wrap_evaluation_matrices\n",
      "    m = create_dmatrix(\n",
      "  File \"c:\\Users\\Administrator\\anaconda3\\envs\\machineind\\lib\\site-packages\\xgboost\\sklearn.py\", line 1065, in _create_dmatrix\n",
      "    return QuantileDMatrix(\n",
      "  File \"c:\\Users\\Administrator\\anaconda3\\envs\\machineind\\lib\\site-packages\\xgboost\\core.py\", line 726, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"c:\\Users\\Administrator\\anaconda3\\envs\\machineind\\lib\\site-packages\\xgboost\\core.py\", line 1573, in __init__\n",
      "    self._init(\n",
      "  File \"c:\\Users\\Administrator\\anaconda3\\envs\\machineind\\lib\\site-packages\\xgboost\\core.py\", line 1632, in _init\n",
      "    it.reraise()\n",
      "  File \"c:\\Users\\Administrator\\anaconda3\\envs\\machineind\\lib\\site-packages\\xgboost\\core.py\", line 569, in reraise\n",
      "    raise exc  # pylint: disable=raising-bad-type\n",
      "  File \"c:\\Users\\Administrator\\anaconda3\\envs\\machineind\\lib\\site-packages\\xgboost\\core.py\", line 550, in _handle_exception\n",
      "    return fn()\n",
      "  File \"c:\\Users\\Administrator\\anaconda3\\envs\\machineind\\lib\\site-packages\\xgboost\\core.py\", line 637, in <lambda>\n",
      "    return self._handle_exception(lambda: self.next(input_data), 0)\n",
      "  File \"c:\\Users\\Administrator\\anaconda3\\envs\\machineind\\lib\\site-packages\\xgboost\\data.py\", line 1402, in next\n",
      "    input_data(**self.kwargs)\n",
      "  File \"c:\\Users\\Administrator\\anaconda3\\envs\\machineind\\lib\\site-packages\\xgboost\\core.py\", line 726, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"c:\\Users\\Administrator\\anaconda3\\envs\\machineind\\lib\\site-packages\\xgboost\\core.py\", line 626, in input_data\n",
      "    self.proxy.set_info(\n",
      "  File \"c:\\Users\\Administrator\\anaconda3\\envs\\machineind\\lib\\site-packages\\xgboost\\core.py\", line 726, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"c:\\Users\\Administrator\\anaconda3\\envs\\machineind\\lib\\site-packages\\xgboost\\core.py\", line 954, in set_info\n",
      "    self.set_label(label)\n",
      "  File \"c:\\Users\\Administrator\\anaconda3\\envs\\machineind\\lib\\site-packages\\xgboost\\core.py\", line 1092, in set_label\n",
      "    dispatch_meta_backend(self, label, \"label\", \"float\")\n",
      "  File \"c:\\Users\\Administrator\\anaconda3\\envs\\machineind\\lib\\site-packages\\xgboost\\data.py\", line 1338, in dispatch_meta_backend\n",
      "    _meta_from_numpy(data, name, dtype, handle)\n",
      "  File \"c:\\Users\\Administrator\\anaconda3\\envs\\machineind\\lib\\site-packages\\xgboost\\data.py\", line 1279, in _meta_from_numpy\n",
      "    _check_call(_LIB.XGDMatrixSetInfoFromInterface(handle, c_str(field), interface_str))\n",
      "  File \"c:\\Users\\Administrator\\anaconda3\\envs\\machineind\\lib\\site-packages\\xgboost\\core.py\", line 284, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [20:50:48] C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\data\\data.cc:508: Check failed: this->labels.Size() % this->num_row_ == 0 (373 vs. 0) : Incorrect size for labels.\n",
      "[W 2025-02-27 20:50:48,355] Trial 0 failed with value None.\n"
     ]
    },
    {
     "ename": "XGBoostError",
     "evalue": "[20:50:48] C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\data\\data.cc:508: Check failed: this->labels.Size() % this->num_row_ == 0 (373 vs. 0) : Incorrect size for labels.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mXGBoostError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[94], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m# Run Optuna optimization\u001b[39;00m\n\u001b[0;32m      2\u001b[0m study \u001b[39m=\u001b[39m optuna\u001b[39m.\u001b[39mcreate_study(direction\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mmaximize\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m----> 3\u001b[0m study\u001b[39m.\u001b[39;49moptimize(objective, n_trials \u001b[39m=\u001b[39;49m \u001b[39m50\u001b[39;49m, timeout\u001b[39m=\u001b[39;49m\u001b[39m1800\u001b[39;49m) \u001b[39m# run 50 trials or max 30mins\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[39m# print best params\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mBest Parameters found: \u001b[39m\u001b[39m'\u001b[39m, study\u001b[39m.\u001b[39mbest_params)\n",
      "File \u001b[1;32mc:\\Users\\Administrator\\anaconda3\\envs\\machineind\\lib\\site-packages\\optuna\\study\\study.py:475\u001b[0m, in \u001b[0;36mStudy.optimize\u001b[1;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[0;32m    373\u001b[0m \u001b[39mdef\u001b[39;00m\u001b[39m \u001b[39m\u001b[39moptimize\u001b[39m(\n\u001b[0;32m    374\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m    375\u001b[0m     func: ObjectiveFuncType,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    382\u001b[0m     show_progress_bar: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m,\n\u001b[0;32m    383\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    384\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[0;32m    385\u001b[0m \n\u001b[0;32m    386\u001b[0m \u001b[39m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    473\u001b[0m \u001b[39m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[0;32m    474\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 475\u001b[0m     _optimize(\n\u001b[0;32m    476\u001b[0m         study\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m,\n\u001b[0;32m    477\u001b[0m         func\u001b[39m=\u001b[39;49mfunc,\n\u001b[0;32m    478\u001b[0m         n_trials\u001b[39m=\u001b[39;49mn_trials,\n\u001b[0;32m    479\u001b[0m         timeout\u001b[39m=\u001b[39;49mtimeout,\n\u001b[0;32m    480\u001b[0m         n_jobs\u001b[39m=\u001b[39;49mn_jobs,\n\u001b[0;32m    481\u001b[0m         catch\u001b[39m=\u001b[39;49m\u001b[39mtuple\u001b[39;49m(catch) \u001b[39mif\u001b[39;49;00m \u001b[39misinstance\u001b[39;49m(catch, Iterable) \u001b[39melse\u001b[39;49;00m (catch,),\n\u001b[0;32m    482\u001b[0m         callbacks\u001b[39m=\u001b[39;49mcallbacks,\n\u001b[0;32m    483\u001b[0m         gc_after_trial\u001b[39m=\u001b[39;49mgc_after_trial,\n\u001b[0;32m    484\u001b[0m         show_progress_bar\u001b[39m=\u001b[39;49mshow_progress_bar,\n\u001b[0;32m    485\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\Administrator\\anaconda3\\envs\\machineind\\lib\\site-packages\\optuna\\study\\_optimize.py:63\u001b[0m, in \u001b[0;36m_optimize\u001b[1;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[0;32m     61\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     62\u001b[0m     \u001b[39mif\u001b[39;00m n_jobs \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m---> 63\u001b[0m         _optimize_sequential(\n\u001b[0;32m     64\u001b[0m             study,\n\u001b[0;32m     65\u001b[0m             func,\n\u001b[0;32m     66\u001b[0m             n_trials,\n\u001b[0;32m     67\u001b[0m             timeout,\n\u001b[0;32m     68\u001b[0m             catch,\n\u001b[0;32m     69\u001b[0m             callbacks,\n\u001b[0;32m     70\u001b[0m             gc_after_trial,\n\u001b[0;32m     71\u001b[0m             reseed_sampler_rng\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m     72\u001b[0m             time_start\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m,\n\u001b[0;32m     73\u001b[0m             progress_bar\u001b[39m=\u001b[39;49mprogress_bar,\n\u001b[0;32m     74\u001b[0m         )\n\u001b[0;32m     75\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     76\u001b[0m         \u001b[39mif\u001b[39;00m n_jobs \u001b[39m==\u001b[39m \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\Administrator\\anaconda3\\envs\\machineind\\lib\\site-packages\\optuna\\study\\_optimize.py:160\u001b[0m, in \u001b[0;36m_optimize_sequential\u001b[1;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[0;32m    157\u001b[0m         \u001b[39mbreak\u001b[39;00m\n\u001b[0;32m    159\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 160\u001b[0m     frozen_trial \u001b[39m=\u001b[39m _run_trial(study, func, catch)\n\u001b[0;32m    161\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m    162\u001b[0m     \u001b[39m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[0;32m    163\u001b[0m     \u001b[39m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n\u001b[0;32m    164\u001b[0m     \u001b[39m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[0;32m    165\u001b[0m     \u001b[39m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[0;32m    166\u001b[0m     \u001b[39mif\u001b[39;00m gc_after_trial:\n",
      "File \u001b[1;32mc:\\Users\\Administrator\\anaconda3\\envs\\machineind\\lib\\site-packages\\optuna\\study\\_optimize.py:248\u001b[0m, in \u001b[0;36m_run_trial\u001b[1;34m(study, func, catch)\u001b[0m\n\u001b[0;32m    241\u001b[0m         \u001b[39massert\u001b[39;00m \u001b[39mFalse\u001b[39;00m, \u001b[39m\"\u001b[39m\u001b[39mShould not reach.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    243\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[0;32m    244\u001b[0m     frozen_trial\u001b[39m.\u001b[39mstate \u001b[39m==\u001b[39m TrialState\u001b[39m.\u001b[39mFAIL\n\u001b[0;32m    245\u001b[0m     \u001b[39mand\u001b[39;00m func_err \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    246\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(func_err, catch)\n\u001b[0;32m    247\u001b[0m ):\n\u001b[1;32m--> 248\u001b[0m     \u001b[39mraise\u001b[39;00m func_err\n\u001b[0;32m    249\u001b[0m \u001b[39mreturn\u001b[39;00m frozen_trial\n",
      "File \u001b[1;32mc:\\Users\\Administrator\\anaconda3\\envs\\machineind\\lib\\site-packages\\optuna\\study\\_optimize.py:197\u001b[0m, in \u001b[0;36m_run_trial\u001b[1;34m(study, func, catch)\u001b[0m\n\u001b[0;32m    195\u001b[0m \u001b[39mwith\u001b[39;00m get_heartbeat_thread(trial\u001b[39m.\u001b[39m_trial_id, study\u001b[39m.\u001b[39m_storage):\n\u001b[0;32m    196\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 197\u001b[0m         value_or_values \u001b[39m=\u001b[39m func(trial)\n\u001b[0;32m    198\u001b[0m     \u001b[39mexcept\u001b[39;00m exceptions\u001b[39m.\u001b[39mTrialPruned \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    199\u001b[0m         \u001b[39m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[0;32m    200\u001b[0m         state \u001b[39m=\u001b[39m TrialState\u001b[39m.\u001b[39mPRUNED\n",
      "Cell \u001b[1;32mIn[93], line 32\u001b[0m, in \u001b[0;36mobjective\u001b[1;34m(trial)\u001b[0m\n\u001b[0;32m     28\u001b[0m y_val_fold \u001b[39m=\u001b[39m y_val_fold\u001b[39m.\u001b[39mvalues\u001b[39m.\u001b[39mravel()\n\u001b[0;32m     31\u001b[0m model \u001b[39m=\u001b[39m xgb\u001b[39m.\u001b[39mXGBClassifier(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparams)\n\u001b[1;32m---> 32\u001b[0m model\u001b[39m.\u001b[39;49mfit(X_train_fold, y_train_fold,\n\u001b[0;32m     33\u001b[0m             eval_set \u001b[39m=\u001b[39;49m [(X_val_fold, y_val_fold)],\n\u001b[0;32m     34\u001b[0m              verbose \u001b[39m=\u001b[39;49m \u001b[39mFalse\u001b[39;49;00m)\n\u001b[0;32m     35\u001b[0m y_pred \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mpredict_proba(X_val_fold)[:, \u001b[39m1\u001b[39m]\n\u001b[0;32m     36\u001b[0m roc_auc_scores\u001b[39m.\u001b[39mappend(roc_auc_score(y_val_fold, y_pred))\n",
      "File \u001b[1;32mc:\\Users\\Administrator\\anaconda3\\envs\\machineind\\lib\\site-packages\\xgboost\\core.py:726\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    724\u001b[0m \u001b[39mfor\u001b[39;00m k, arg \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(sig\u001b[39m.\u001b[39mparameters, args):\n\u001b[0;32m    725\u001b[0m     kwargs[k] \u001b[39m=\u001b[39m arg\n\u001b[1;32m--> 726\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Administrator\\anaconda3\\envs\\machineind\\lib\\site-packages\\xgboost\\sklearn.py:1580\u001b[0m, in \u001b[0;36mXGBClassifier.fit\u001b[1;34m(self, X, y, sample_weight, base_margin, eval_set, verbose, xgb_model, sample_weight_eval_set, base_margin_eval_set, feature_weights)\u001b[0m\n\u001b[0;32m   1577\u001b[0m     params[\u001b[39m\"\u001b[39m\u001b[39mnum_class\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_classes_\n\u001b[0;32m   1579\u001b[0m model, metric, params \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_configure_fit(xgb_model, params)\n\u001b[1;32m-> 1580\u001b[0m train_dmatrix, evals \u001b[39m=\u001b[39m _wrap_evaluation_matrices(\n\u001b[0;32m   1581\u001b[0m     missing\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmissing,\n\u001b[0;32m   1582\u001b[0m     X\u001b[39m=\u001b[39;49mX,\n\u001b[0;32m   1583\u001b[0m     y\u001b[39m=\u001b[39;49my,\n\u001b[0;32m   1584\u001b[0m     group\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m,\n\u001b[0;32m   1585\u001b[0m     qid\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m,\n\u001b[0;32m   1586\u001b[0m     sample_weight\u001b[39m=\u001b[39;49msample_weight,\n\u001b[0;32m   1587\u001b[0m     base_margin\u001b[39m=\u001b[39;49mbase_margin,\n\u001b[0;32m   1588\u001b[0m     feature_weights\u001b[39m=\u001b[39;49mfeature_weights,\n\u001b[0;32m   1589\u001b[0m     eval_set\u001b[39m=\u001b[39;49meval_set,\n\u001b[0;32m   1590\u001b[0m     sample_weight_eval_set\u001b[39m=\u001b[39;49msample_weight_eval_set,\n\u001b[0;32m   1591\u001b[0m     base_margin_eval_set\u001b[39m=\u001b[39;49mbase_margin_eval_set,\n\u001b[0;32m   1592\u001b[0m     eval_group\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m,\n\u001b[0;32m   1593\u001b[0m     eval_qid\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m,\n\u001b[0;32m   1594\u001b[0m     create_dmatrix\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_create_dmatrix,\n\u001b[0;32m   1595\u001b[0m     enable_categorical\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49menable_categorical,\n\u001b[0;32m   1596\u001b[0m     feature_types\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfeature_types,\n\u001b[0;32m   1597\u001b[0m )\n\u001b[0;32m   1599\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_Booster \u001b[39m=\u001b[39m train(\n\u001b[0;32m   1600\u001b[0m     params,\n\u001b[0;32m   1601\u001b[0m     train_dmatrix,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1610\u001b[0m     callbacks\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcallbacks,\n\u001b[0;32m   1611\u001b[0m )\n\u001b[0;32m   1613\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mcallable\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobjective):\n",
      "File \u001b[1;32mc:\\Users\\Administrator\\anaconda3\\envs\\machineind\\lib\\site-packages\\xgboost\\sklearn.py:654\u001b[0m, in \u001b[0;36m_wrap_evaluation_matrices\u001b[1;34m(missing, X, y, group, qid, sample_weight, base_margin, feature_weights, eval_set, sample_weight_eval_set, base_margin_eval_set, eval_group, eval_qid, create_dmatrix, enable_categorical, feature_types)\u001b[0m\n\u001b[0;32m    652\u001b[0m         evals\u001b[39m.\u001b[39mappend(train_dmatrix)\n\u001b[0;32m    653\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 654\u001b[0m         m \u001b[39m=\u001b[39m create_dmatrix(\n\u001b[0;32m    655\u001b[0m             data\u001b[39m=\u001b[39;49mvalid_X,\n\u001b[0;32m    656\u001b[0m             label\u001b[39m=\u001b[39;49mvalid_y,\n\u001b[0;32m    657\u001b[0m             weight\u001b[39m=\u001b[39;49msample_weight_eval_set[i],\n\u001b[0;32m    658\u001b[0m             group\u001b[39m=\u001b[39;49meval_group[i],\n\u001b[0;32m    659\u001b[0m             qid\u001b[39m=\u001b[39;49meval_qid[i],\n\u001b[0;32m    660\u001b[0m             base_margin\u001b[39m=\u001b[39;49mbase_margin_eval_set[i],\n\u001b[0;32m    661\u001b[0m             missing\u001b[39m=\u001b[39;49mmissing,\n\u001b[0;32m    662\u001b[0m             enable_categorical\u001b[39m=\u001b[39;49menable_categorical,\n\u001b[0;32m    663\u001b[0m             feature_types\u001b[39m=\u001b[39;49mfeature_types,\n\u001b[0;32m    664\u001b[0m             ref\u001b[39m=\u001b[39;49mtrain_dmatrix,\n\u001b[0;32m    665\u001b[0m         )\n\u001b[0;32m    666\u001b[0m         evals\u001b[39m.\u001b[39mappend(m)\n\u001b[0;32m    667\u001b[0m nevals \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(evals)\n",
      "File \u001b[1;32mc:\\Users\\Administrator\\anaconda3\\envs\\machineind\\lib\\site-packages\\xgboost\\sklearn.py:1065\u001b[0m, in \u001b[0;36mXGBModel._create_dmatrix\u001b[1;34m(self, ref, **kwargs)\u001b[0m\n\u001b[0;32m   1063\u001b[0m \u001b[39mif\u001b[39;00m _can_use_qdm(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtree_method) \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbooster \u001b[39m!=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mgblinear\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m   1064\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 1065\u001b[0m         \u001b[39mreturn\u001b[39;00m QuantileDMatrix(\n\u001b[0;32m   1066\u001b[0m             \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs, ref\u001b[39m=\u001b[39mref, nthread\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_jobs, max_bin\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmax_bin\n\u001b[0;32m   1067\u001b[0m         )\n\u001b[0;32m   1068\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:  \u001b[39m# `QuantileDMatrix` supports lesser types than DMatrix\u001b[39;00m\n\u001b[0;32m   1069\u001b[0m         \u001b[39mpass\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Administrator\\anaconda3\\envs\\machineind\\lib\\site-packages\\xgboost\\core.py:726\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    724\u001b[0m \u001b[39mfor\u001b[39;00m k, arg \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(sig\u001b[39m.\u001b[39mparameters, args):\n\u001b[0;32m    725\u001b[0m     kwargs[k] \u001b[39m=\u001b[39m arg\n\u001b[1;32m--> 726\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Administrator\\anaconda3\\envs\\machineind\\lib\\site-packages\\xgboost\\core.py:1573\u001b[0m, in \u001b[0;36mQuantileDMatrix.__init__\u001b[1;34m(self, data, label, weight, base_margin, missing, silent, feature_names, feature_types, nthread, max_bin, ref, group, qid, label_lower_bound, label_upper_bound, feature_weights, enable_categorical, data_split_mode)\u001b[0m\n\u001b[0;32m   1553\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39many\u001b[39m(\n\u001b[0;32m   1554\u001b[0m         info \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m   1555\u001b[0m         \u001b[39mfor\u001b[39;00m info \u001b[39min\u001b[39;00m (\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1566\u001b[0m         )\n\u001b[0;32m   1567\u001b[0m     ):\n\u001b[0;32m   1568\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m   1569\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mIf data iterator is used as input, data like label should be \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1570\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mspecified as batch argument.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1571\u001b[0m         )\n\u001b[1;32m-> 1573\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_init(\n\u001b[0;32m   1574\u001b[0m     data,\n\u001b[0;32m   1575\u001b[0m     ref\u001b[39m=\u001b[39;49mref,\n\u001b[0;32m   1576\u001b[0m     label\u001b[39m=\u001b[39;49mlabel,\n\u001b[0;32m   1577\u001b[0m     weight\u001b[39m=\u001b[39;49mweight,\n\u001b[0;32m   1578\u001b[0m     base_margin\u001b[39m=\u001b[39;49mbase_margin,\n\u001b[0;32m   1579\u001b[0m     group\u001b[39m=\u001b[39;49mgroup,\n\u001b[0;32m   1580\u001b[0m     qid\u001b[39m=\u001b[39;49mqid,\n\u001b[0;32m   1581\u001b[0m     label_lower_bound\u001b[39m=\u001b[39;49mlabel_lower_bound,\n\u001b[0;32m   1582\u001b[0m     label_upper_bound\u001b[39m=\u001b[39;49mlabel_upper_bound,\n\u001b[0;32m   1583\u001b[0m     feature_weights\u001b[39m=\u001b[39;49mfeature_weights,\n\u001b[0;32m   1584\u001b[0m     feature_names\u001b[39m=\u001b[39;49mfeature_names,\n\u001b[0;32m   1585\u001b[0m     feature_types\u001b[39m=\u001b[39;49mfeature_types,\n\u001b[0;32m   1586\u001b[0m     enable_categorical\u001b[39m=\u001b[39;49menable_categorical,\n\u001b[0;32m   1587\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\Administrator\\anaconda3\\envs\\machineind\\lib\\site-packages\\xgboost\\core.py:1632\u001b[0m, in \u001b[0;36mQuantileDMatrix._init\u001b[1;34m(self, data, ref, enable_categorical, **meta)\u001b[0m\n\u001b[0;32m   1620\u001b[0m config \u001b[39m=\u001b[39m make_jcargs(\n\u001b[0;32m   1621\u001b[0m     nthread\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnthread, missing\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmissing, max_bin\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmax_bin\n\u001b[0;32m   1622\u001b[0m )\n\u001b[0;32m   1623\u001b[0m ret \u001b[39m=\u001b[39m _LIB\u001b[39m.\u001b[39mXGQuantileDMatrixCreateFromCallback(\n\u001b[0;32m   1624\u001b[0m     \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m   1625\u001b[0m     it\u001b[39m.\u001b[39mproxy\u001b[39m.\u001b[39mhandle,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1630\u001b[0m     ctypes\u001b[39m.\u001b[39mbyref(handle),\n\u001b[0;32m   1631\u001b[0m )\n\u001b[1;32m-> 1632\u001b[0m it\u001b[39m.\u001b[39;49mreraise()\n\u001b[0;32m   1633\u001b[0m \u001b[39m# delay check_call to throw intermediate exception first\u001b[39;00m\n\u001b[0;32m   1634\u001b[0m _check_call(ret)\n",
      "File \u001b[1;32mc:\\Users\\Administrator\\anaconda3\\envs\\machineind\\lib\\site-packages\\xgboost\\core.py:569\u001b[0m, in \u001b[0;36mDataIter.reraise\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    567\u001b[0m exc \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_exception\n\u001b[0;32m    568\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_exception \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m--> 569\u001b[0m \u001b[39mraise\u001b[39;00m exc\n",
      "File \u001b[1;32mc:\\Users\\Administrator\\anaconda3\\envs\\machineind\\lib\\site-packages\\xgboost\\core.py:550\u001b[0m, in \u001b[0;36mDataIter._handle_exception\u001b[1;34m(self, fn, dft_ret)\u001b[0m\n\u001b[0;32m    547\u001b[0m     \u001b[39mreturn\u001b[39;00m dft_ret\n\u001b[0;32m    549\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 550\u001b[0m     \u001b[39mreturn\u001b[39;00m fn()\n\u001b[0;32m    551\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m    552\u001b[0m     \u001b[39m# Defer the exception in order to return 0 and stop the iteration.\u001b[39;00m\n\u001b[0;32m    553\u001b[0m     \u001b[39m# Exception inside a ctype callback function has no effect except\u001b[39;00m\n\u001b[0;32m    554\u001b[0m     \u001b[39m# for printing to stderr (doesn't stop the execution).\u001b[39;00m\n\u001b[0;32m    555\u001b[0m     tb \u001b[39m=\u001b[39m sys\u001b[39m.\u001b[39mexc_info()[\u001b[39m2\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\Administrator\\anaconda3\\envs\\machineind\\lib\\site-packages\\xgboost\\core.py:637\u001b[0m, in \u001b[0;36mDataIter._next_wrapper.<locals>.<lambda>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    635\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_temporary_data \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    636\u001b[0m \u001b[39m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m--> 637\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_handle_exception(\u001b[39mlambda\u001b[39;00m: \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnext(input_data), \u001b[39m0\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Administrator\\anaconda3\\envs\\machineind\\lib\\site-packages\\xgboost\\data.py:1402\u001b[0m, in \u001b[0;36mSingleBatchInternalIter.next\u001b[1;34m(self, input_data)\u001b[0m\n\u001b[0;32m   1400\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39m0\u001b[39m\n\u001b[0;32m   1401\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mit \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m-> 1402\u001b[0m input_data(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mkwargs)\n\u001b[0;32m   1403\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39m1\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\Administrator\\anaconda3\\envs\\machineind\\lib\\site-packages\\xgboost\\core.py:726\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    724\u001b[0m \u001b[39mfor\u001b[39;00m k, arg \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(sig\u001b[39m.\u001b[39mparameters, args):\n\u001b[0;32m    725\u001b[0m     kwargs[k] \u001b[39m=\u001b[39m arg\n\u001b[1;32m--> 726\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Administrator\\anaconda3\\envs\\machineind\\lib\\site-packages\\xgboost\\core.py:626\u001b[0m, in \u001b[0;36mDataIter._next_wrapper.<locals>.input_data\u001b[1;34m(data, feature_names, feature_types, **kwargs)\u001b[0m\n\u001b[0;32m    624\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_temporary_data \u001b[39m=\u001b[39m (new, cat_codes, feature_names, feature_types)\n\u001b[0;32m    625\u001b[0m dispatch_proxy_set_data(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mproxy, new, cat_codes)\n\u001b[1;32m--> 626\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mproxy\u001b[39m.\u001b[39mset_info(\n\u001b[0;32m    627\u001b[0m     feature_names\u001b[39m=\u001b[39mfeature_names,\n\u001b[0;32m    628\u001b[0m     feature_types\u001b[39m=\u001b[39mfeature_types,\n\u001b[0;32m    629\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[0;32m    630\u001b[0m )\n\u001b[0;32m    631\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_data_ref \u001b[39m=\u001b[39m ref\n",
      "File \u001b[1;32mc:\\Users\\Administrator\\anaconda3\\envs\\machineind\\lib\\site-packages\\xgboost\\core.py:726\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    724\u001b[0m \u001b[39mfor\u001b[39;00m k, arg \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(sig\u001b[39m.\u001b[39mparameters, args):\n\u001b[0;32m    725\u001b[0m     kwargs[k] \u001b[39m=\u001b[39m arg\n\u001b[1;32m--> 726\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Administrator\\anaconda3\\envs\\machineind\\lib\\site-packages\\xgboost\\core.py:954\u001b[0m, in \u001b[0;36mDMatrix.set_info\u001b[1;34m(self, label, weight, base_margin, group, qid, label_lower_bound, label_upper_bound, feature_names, feature_types, feature_weights)\u001b[0m\n\u001b[0;32m    951\u001b[0m \u001b[39mfrom\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m.\u001b[39;00m\u001b[39mdata\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mimport\u001b[39;00m dispatch_meta_backend\n\u001b[0;32m    953\u001b[0m \u001b[39mif\u001b[39;00m label \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 954\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mset_label(label)\n\u001b[0;32m    955\u001b[0m \u001b[39mif\u001b[39;00m weight \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    956\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mset_weight(weight)\n",
      "File \u001b[1;32mc:\\Users\\Administrator\\anaconda3\\envs\\machineind\\lib\\site-packages\\xgboost\\core.py:1092\u001b[0m, in \u001b[0;36mDMatrix.set_label\u001b[1;34m(self, label)\u001b[0m\n\u001b[0;32m   1083\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Set label of dmatrix\u001b[39;00m\n\u001b[0;32m   1084\u001b[0m \n\u001b[0;32m   1085\u001b[0m \u001b[39mParameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1088\u001b[0m \u001b[39m    The label information to be set into DMatrix\u001b[39;00m\n\u001b[0;32m   1089\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   1090\u001b[0m \u001b[39mfrom\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m.\u001b[39;00m\u001b[39mdata\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mimport\u001b[39;00m dispatch_meta_backend\n\u001b[1;32m-> 1092\u001b[0m dispatch_meta_backend(\u001b[39mself\u001b[39;49m, label, \u001b[39m\"\u001b[39;49m\u001b[39mlabel\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mfloat\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n",
      "File \u001b[1;32mc:\\Users\\Administrator\\anaconda3\\envs\\machineind\\lib\\site-packages\\xgboost\\data.py:1338\u001b[0m, in \u001b[0;36mdispatch_meta_backend\u001b[1;34m(matrix, data, name, dtype)\u001b[0m\n\u001b[0;32m   1336\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[0;32m   1337\u001b[0m \u001b[39mif\u001b[39;00m _is_np_array_like(data):\n\u001b[1;32m-> 1338\u001b[0m     _meta_from_numpy(data, name, dtype, handle)\n\u001b[0;32m   1339\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[0;32m   1340\u001b[0m \u001b[39mif\u001b[39;00m _is_arrow(data):\n",
      "File \u001b[1;32mc:\\Users\\Administrator\\anaconda3\\envs\\machineind\\lib\\site-packages\\xgboost\\data.py:1279\u001b[0m, in \u001b[0;36m_meta_from_numpy\u001b[1;34m(data, field, dtype, handle)\u001b[0m\n\u001b[0;32m   1277\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mMasked array is not supported.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m   1278\u001b[0m interface_str \u001b[39m=\u001b[39m _array_interface(data)\n\u001b[1;32m-> 1279\u001b[0m _check_call(_LIB\u001b[39m.\u001b[39;49mXGDMatrixSetInfoFromInterface(handle, c_str(field), interface_str))\n",
      "File \u001b[1;32mc:\\Users\\Administrator\\anaconda3\\envs\\machineind\\lib\\site-packages\\xgboost\\core.py:284\u001b[0m, in \u001b[0;36m_check_call\u001b[1;34m(ret)\u001b[0m\n\u001b[0;32m    273\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Check the return value of C API call\u001b[39;00m\n\u001b[0;32m    274\u001b[0m \n\u001b[0;32m    275\u001b[0m \u001b[39mThis function will raise exception when error occurs.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    281\u001b[0m \u001b[39m    return value from API calls\u001b[39;00m\n\u001b[0;32m    282\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    283\u001b[0m \u001b[39mif\u001b[39;00m ret \u001b[39m!=\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m--> 284\u001b[0m     \u001b[39mraise\u001b[39;00m XGBoostError(py_str(_LIB\u001b[39m.\u001b[39mXGBGetLastError()))\n",
      "\u001b[1;31mXGBoostError\u001b[0m: [20:50:48] C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\data\\data.cc:508: Check failed: this->labels.Size() % this->num_row_ == 0 (373 vs. 0) : Incorrect size for labels."
     ]
    }
   ],
   "source": [
    "# Run Optuna optimization\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials = 50, timeout=1800) # run 50 trials or max 30mins\n",
    "\n",
    "# print best params\n",
    "print('Best Parameters found: ', study.best_params)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(933, 12) (933, 12) (933,) (932,)\n"
     ]
    }
   ],
   "source": [
    " # instantiate the kfold\n",
    "strat_kfold = StratifiedKFold(n_splits=2, shuffle=True, random_state=42)\n",
    "#roc_auc_scores = []    # instatntiate an empty list to store the roc_auc scores\n",
    "\n",
    "for train_index, val_index in strat_kfold.split(X_train, y_train):\n",
    "    X_train_fold, X_val_fold = X_train.iloc[train_index], X_train.iloc[train_index]\n",
    "    y_train_fold, y_val_fold = y_train.iloc[train_index], y_train.iloc[val_index]\n",
    "    \n",
    "print(X_train_fold.shape, X_val_fold.shape, y_train_fold.shape, y_val_fold.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1492, 12) (373, 12) (1492,) (373,)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "# Ensure X_train and y_train are Pandas DataFrame/Series\n",
    "if isinstance(X_train, np.ndarray):\n",
    "    X_train = pd.DataFrame(X_train)\n",
    "if isinstance(y_train, np.ndarray):\n",
    "    y_train = pd.Series(y_train)\n",
    "\n",
    "# Instantiate Stratified K-Fold\n",
    "strat_kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "for train_index, val_index in strat_kfold.split(X_train, y_train):\n",
    "    X_train_fold, X_val_fold = X_train.iloc[train_index], X_train.iloc[val_index]\n",
    "    y_train_fold, y_val_fold = y_train.iloc[train_index], y_train.iloc[val_index]\n",
    "\n",
    "print(X_train_fold.shape, X_val_fold.shape, y_train_fold.shape, y_val_fold.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "machineind",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
