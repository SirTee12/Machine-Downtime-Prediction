{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine Learning Model Development"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Import the necessary libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Administrator\\anaconda3\\envs\\machineind\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold, StratifiedShuffleSplit,\\\n",
    "                                    cross_val_predict\n",
    "from sklearn.preprocessing import RobustScaler, StandardScaler, LabelEncoder, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import accuracy_score, precision_score,\\\n",
    "                            recall_score, f1_score, roc_auc_score\n",
    "        \n",
    "\n",
    "import optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Machine_ID</th>\n",
       "      <th>Assembly_Line_No</th>\n",
       "      <th>Coolant_Temperature</th>\n",
       "      <th>Hydraulic_Oil_Temperature</th>\n",
       "      <th>Spindle_Bearing_Temperature</th>\n",
       "      <th>Spindle_Vibration</th>\n",
       "      <th>Tool_Vibration</th>\n",
       "      <th>Voltage(volts)</th>\n",
       "      <th>Torque(Nm)</th>\n",
       "      <th>Downtime</th>\n",
       "      <th>Hydraulic_Pressure(Pa)</th>\n",
       "      <th>Coolant_Pressure(Pa)</th>\n",
       "      <th>Air_System_Pressure(Pa)</th>\n",
       "      <th>Cutting(N)</th>\n",
       "      <th>Spindle_Speed(RPS)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-12-08</td>\n",
       "      <td>Makino-L2-Unit1-2015</td>\n",
       "      <td>Shopfloor-L2</td>\n",
       "      <td>4.5</td>\n",
       "      <td>47.9</td>\n",
       "      <td>31.2</td>\n",
       "      <td>1.225</td>\n",
       "      <td>35.214</td>\n",
       "      <td>381.0</td>\n",
       "      <td>23.091903</td>\n",
       "      <td>No_Machine_Failure</td>\n",
       "      <td>14115919.3</td>\n",
       "      <td>513860.1</td>\n",
       "      <td>612765.0</td>\n",
       "      <td>2870.0</td>\n",
       "      <td>253.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-12-17</td>\n",
       "      <td>Makino-L2-Unit1-2015</td>\n",
       "      <td>Shopfloor-L2</td>\n",
       "      <td>21.7</td>\n",
       "      <td>47.5</td>\n",
       "      <td>35.8</td>\n",
       "      <td>1.078</td>\n",
       "      <td>29.198</td>\n",
       "      <td>367.0</td>\n",
       "      <td>31.620335</td>\n",
       "      <td>No_Machine_Failure</td>\n",
       "      <td>7246602.0</td>\n",
       "      <td>514111.3</td>\n",
       "      <td>662932.2</td>\n",
       "      <td>2970.0</td>\n",
       "      <td>295.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-12-17</td>\n",
       "      <td>Makino-L1-Unit1-2013</td>\n",
       "      <td>Shopfloor-L1</td>\n",
       "      <td>5.2</td>\n",
       "      <td>49.4</td>\n",
       "      <td>34.2</td>\n",
       "      <td>1.266</td>\n",
       "      <td>30.206</td>\n",
       "      <td>340.0</td>\n",
       "      <td>15.900716</td>\n",
       "      <td>Machine_Failure</td>\n",
       "      <td>8828000.0</td>\n",
       "      <td>683941.3</td>\n",
       "      <td>656038.1</td>\n",
       "      <td>2700.0</td>\n",
       "      <td>466.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-12-17</td>\n",
       "      <td>Makino-L1-Unit1-2013</td>\n",
       "      <td>Shopfloor-L1</td>\n",
       "      <td>24.4</td>\n",
       "      <td>48.1</td>\n",
       "      <td>36.6</td>\n",
       "      <td>0.778</td>\n",
       "      <td>25.048</td>\n",
       "      <td>307.0</td>\n",
       "      <td>23.923929</td>\n",
       "      <td>Machine_Failure</td>\n",
       "      <td>7454000.0</td>\n",
       "      <td>658019.5</td>\n",
       "      <td>652883.7</td>\n",
       "      <td>3590.0</td>\n",
       "      <td>466.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-12-21</td>\n",
       "      <td>Makino-L2-Unit1-2015</td>\n",
       "      <td>Shopfloor-L2</td>\n",
       "      <td>14.1</td>\n",
       "      <td>51.8</td>\n",
       "      <td>32.4</td>\n",
       "      <td>0.969</td>\n",
       "      <td>31.491</td>\n",
       "      <td>380.0</td>\n",
       "      <td>16.964105</td>\n",
       "      <td>Machine_Failure</td>\n",
       "      <td>5326000.0</td>\n",
       "      <td>683941.3</td>\n",
       "      <td>602069.0</td>\n",
       "      <td>2860.0</td>\n",
       "      <td>460.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Date            Machine_ID Assembly_Line_No  Coolant_Temperature  \\\n",
       "0 2021-12-08  Makino-L2-Unit1-2015     Shopfloor-L2                  4.5   \n",
       "1 2021-12-17  Makino-L2-Unit1-2015     Shopfloor-L2                 21.7   \n",
       "2 2021-12-17  Makino-L1-Unit1-2013     Shopfloor-L1                  5.2   \n",
       "3 2021-12-17  Makino-L1-Unit1-2013     Shopfloor-L1                 24.4   \n",
       "4 2021-12-21  Makino-L2-Unit1-2015     Shopfloor-L2                 14.1   \n",
       "\n",
       "   Hydraulic_Oil_Temperature  Spindle_Bearing_Temperature  Spindle_Vibration  \\\n",
       "0                       47.9                         31.2              1.225   \n",
       "1                       47.5                         35.8              1.078   \n",
       "2                       49.4                         34.2              1.266   \n",
       "3                       48.1                         36.6              0.778   \n",
       "4                       51.8                         32.4              0.969   \n",
       "\n",
       "   Tool_Vibration  Voltage(volts)  Torque(Nm)            Downtime  \\\n",
       "0          35.214           381.0   23.091903  No_Machine_Failure   \n",
       "1          29.198           367.0   31.620335  No_Machine_Failure   \n",
       "2          30.206           340.0   15.900716     Machine_Failure   \n",
       "3          25.048           307.0   23.923929     Machine_Failure   \n",
       "4          31.491           380.0   16.964105     Machine_Failure   \n",
       "\n",
       "   Hydraulic_Pressure(Pa)  Coolant_Pressure(Pa)  Air_System_Pressure(Pa)  \\\n",
       "0              14115919.3              513860.1                 612765.0   \n",
       "1               7246602.0              514111.3                 662932.2   \n",
       "2               8828000.0              683941.3                 656038.1   \n",
       "3               7454000.0              658019.5                 652883.7   \n",
       "4               5326000.0              683941.3                 602069.0   \n",
       "\n",
       "   Cutting(N)  Spindle_Speed(RPS)  \n",
       "0      2870.0               253.6  \n",
       "1      2970.0               295.4  \n",
       "2      2700.0               466.0  \n",
       "3      3590.0               466.0  \n",
       "4      2860.0               460.2  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the dataset\n",
    "machine = pd.read_csv(\"../data/machine_downtime_cleaned.csv\", parse_dates=['Date'])\n",
    "\n",
    "# make a copy of the data \n",
    "machine_ori = machine.copy()\n",
    "# print the first few rows\n",
    "machine.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing\n",
    "\n",
    "we have to divide the numeric columns into those that are skewed and those that are normal in order to be able to apply the necessary standardization or normalization to avoid bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coolant_Temperature: Skewness = -0.22, Kurtosis = -1.35 (Not Normally Distributed)\n",
      "Hydraulic_Oil_Temperature: Skewness = -0.00, Kurtosis = 0.05 (Approximately Normal)\n",
      "Spindle_Bearing_Temperature: Skewness = -0.03, Kurtosis = -0.05 (Approximately Normal)\n",
      "Spindle_Vibration: Skewness = 0.03, Kurtosis = -0.11 (Approximately Normal)\n",
      "Tool_Vibration: Skewness = -0.06, Kurtosis = 0.01 (Approximately Normal)\n",
      "Voltage(volts): Skewness = -0.03, Kurtosis = -0.09 (Approximately Normal)\n",
      "Torque(Nm): Skewness = 0.03, Kurtosis = -0.46 (Not Normally Distributed)\n",
      "Hydraulic_Pressure(Pa): Skewness = 0.21, Kurtosis = -0.98 (Not Normally Distributed)\n",
      "Coolant_Pressure(Pa): Skewness = -0.01, Kurtosis = -0.13 (Approximately Normal)\n",
      "Air_System_Pressure(Pa): Skewness = -0.05, Kurtosis = 0.01 (Approximately Normal)\n",
      "Cutting(N): Skewness = 0.12, Kurtosis = -1.09 (Not Normally Distributed)\n",
      "Spindle_Speed(RPS): Skewness = 0.22, Kurtosis = -0.45 (Not Normally Distributed)\n"
     ]
    }
   ],
   "source": [
    "# create an empty list to store columns that are normally or\n",
    "# skewly distributed\n",
    "normal_cols = []\n",
    "skewed_cols = []\n",
    "\n",
    "# loop through the numerical features\n",
    "for col in machine_ori.select_dtypes(include=np.number):\n",
    "    skewness = machine_ori[col].skew()\n",
    "    kurtosis = machine_ori[col].kurt()\n",
    "\n",
    "    # set a threshold for kurtosis and skewness and then append the necessary features\n",
    "    if -0.2 <= skewness <= 0.3 and -0.2 <= kurtosis <= 0.2:  # Adjust thresholds as needed\n",
    "        normal_cols.append(col)\n",
    "        print(f\"{col}: Skewness = {skewness:.2f}, Kurtosis = {kurtosis:.2f} (Approximately Normal)\")\n",
    "    else:\n",
    "        skewed_cols.append(col)\n",
    "        print(f\"{col}: Skewness = {skewness:.2f}, Kurtosis = {kurtosis:.2f} (Not Normally Distributed)\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Parameters Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define target and features\n",
    "X = machine_ori.drop(columns=[\"Downtime\", \"Date\", \"Assembly_Line_No\"])  # Features\n",
    "\n",
    "# define encoder\n",
    "label_encode = LabelEncoder()\n",
    "y = label_encode.fit_transform(machine_ori[\"Downtime\"])  # Target variable\n",
    "\n",
    "# Identify numerical and categorical columns\n",
    "numerical_cols = X.select_dtypes(include=['float64', 'int64']).columns\n",
    "category_col = X.select_dtypes(include=['object']).columns\n",
    "\n",
    "# Define transformers\n",
    "preprocessor = ColumnTransformer([\n",
    "    (\"robust\", RobustScaler(), skewed_cols),  # Skewed data\n",
    "    (\"standard\", StandardScaler(), normal_cols),  # Normal data \n",
    "    ('one-hot-encoder', OneHotEncoder(), category_col) # Machine_ID column\n",
    "])\n",
    "\n",
    "# Train-test split\n",
    "# Step 1: Split into Train (60%), Validation (20%), Test (20%)\n",
    "X_train_val, X_test, y_train_val, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train_val, y_train_val, test_size=0.25, stratify=y_train_val, random_state=42)\n",
    "\n",
    "# Define models\n",
    "models = {\n",
    "    \"Bayesian Logistic Regression\": LogisticRegression(solver=\"lbfgs\"),\n",
    "    \"Random Forest\": RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "    \"Gradient Boosting\": GradientBoostingClassifier(n_estimators=100, random_state=42),\n",
    "    \"Decision Tree\": DecisionTreeClassifier(random_state=42),\n",
    "    \"SVM\": SVC(kernel=\"rbf\", probability=True, random_state=42),\n",
    "    \"XGBoost\": xgb.XGBClassifier(eval_metric=\"auc\", random_state = 42)\n",
    "}\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the model \n",
    "#### Cross Validation\n",
    "\n",
    "Since our problem is a classification task, Stratified K-Fold (StratifiedKFold) will be use for the cross validation. \n",
    "\n",
    "Why Use Stratified K-Fold?\n",
    "\n",
    "+ Preserves Class Distribution: Stratified K-Fold ensures that each fold maintains the same proportion of classes as the overall dataset, which is crucial when dealing with classification problems, even if there is no visible class imbalance.\n",
    "+ More Reliable Performance Estimates: It provides a more stable and representative estimate of your model’s performance compared to ShuffleSplit, which may produce folds with different class distributions.\n",
    "+ Better Generalization: Ensures that all classes are well represented in training and validation splits, reducing the risk of biased results.\n",
    "\n",
    "**Key Performance Metrics and Their Meaning**\n",
    "\n",
    "+ Precision: Measures how many of the predicted failures were actually failures. A high precision means fewer false positives.\n",
    "+ Recall: Measures how many of the actual failures were correctly identified. A high recall means fewer false negatives.\n",
    "+ F1-Score: Harmonic mean of precision and recall, balancing both. Higher is better.\n",
    "+ ROC AUC: Measures the model’s ability to distinguish between classes. A value closer to 1 is better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# craete an empty list to store model result\n",
    "model_results = []\n",
    "\n",
    "# Initialize Stratified K-Fold\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "for name, model in models.items():\n",
    "    precision_scores, recall_scores, f1_scores, roc_auc_scores = [], [], [], []\n",
    "\n",
    "    for train_index, val_index in cv.split(X_train_val, y_train_val):\n",
    "        X_train_fold, X_val_fold = X_train_val.iloc[train_index], X_train_val.iloc[val_index]\n",
    "        y_train_fold, y_val_fold = y_train_val[train_index], y_train_val[val_index]\n",
    "\n",
    "        # Create a pipeline\n",
    "        pipeline = Pipeline([\n",
    "            ('preprocessor', preprocessor),\n",
    "            ('classifier', model)\n",
    "        ])\n",
    "\n",
    "        # Train the model\n",
    "        pipeline.fit(X_train_fold, y_train_fold)\n",
    "\n",
    "        # Make predictions\n",
    "        y_pred = pipeline.predict(X_val_fold)\n",
    "        y_prob = pipeline.predict_proba(X_val_fold)[:, 1] if hasattr(model, 'predict_proba') else None\n",
    "\n",
    "        # Evaluate Metrics\n",
    "        precision_scores.append(precision_score(y_val_fold, y_pred))\n",
    "        recall_scores.append(recall_score(y_val_fold, y_pred))\n",
    "        f1_scores.append(f1_score(y_val_fold, y_pred))\n",
    "        roc_auc_scores.append(roc_auc_score(y_val_fold, y_prob) if y_prob is not None else np.nan)\n",
    "\n",
    "    # Compute mean scores across folds\n",
    "    mean_precision = np.mean(precision_scores)\n",
    "    mean_recall = np.mean(recall_scores)\n",
    "    mean_f1 = np.mean(f1_scores)\n",
    "    mean_roc_auc = np.nanmean(roc_auc_scores)\n",
    "\n",
    "    # Append results\n",
    "    model_results.append({\n",
    "        \"Model\": name,\n",
    "        \"Precision\": round(mean_precision, 4),\n",
    "        \"Recall\": round(mean_recall, 4),\n",
    "        \"F1-Score\": round(mean_f1, 4),\n",
    "        \"ROC AUC\": round(mean_roc_auc, 4)\n",
    "    })\n",
    "\n",
    "\n",
    "# Convert results to DataFrame\n",
    "model_results_df = pd.DataFrame(model_results)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Performance and Best Result\n",
    "\n",
    "**Model Performance Interpretation**\n",
    "\n",
    "1. XGBoost (0.9993 ROC AUC, 0.9919 F1-Score)\n",
    "> + Remains a top performer with exceptional discrimination ability (ROC AUC) and a near-perfect balance of precision and recall (F1-Score).\n",
    "> + It's likely to generalize well to the test set.\n",
    "\n",
    "2. Random Forest (0.9990 ROC AUC, 0.9858 F1-Score)\n",
    "> + Also demonstrates excellent performance, very close to XGBoost.\n",
    "> + If interpretability is crucial, it might be preferable.\n",
    "\n",
    "3. Gradient Boosting (0.9991 ROC AUC, 0.9919 F1-Score)\n",
    "> + Achieves top-tier performance, comparable to XGBoost, with a slight edge in recall.\n",
    "\n",
    "4. Decision Tree (0.9694 ROC AUC, 0.9692 F1-Score)\n",
    "> + Shows good performance but falls short compared to the ensemble methods (XGBoost, Random Forest, Gradient Boosting).\n",
    "\n",
    "5. SVM (0.9439 ROC AUC, 0.8779 F1-Score)\n",
    "> + Exhibits decent performance but is outperformed by the ensemble models.\n",
    "\n",
    "6. Bayesian Logistic Regression (0.9292 ROC AUC, 0.8625 F1-Score)\n",
    "> + Shows moderate performance, lagging behind the other models.\n",
    "\n",
    "**Observations**\n",
    "> + Ensemble methods (XGBoost, Random Forest, Gradient Boosting) consistently outperform the single models (Decision Tree, SVM, Bayesian Logistic Regression).\n",
    "> + XGBoost, Random Forest, and Gradient Boosting have shown remarkable performance, with very high ROC AUC and F1-Scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1-Score</th>\n",
       "      <th>ROC AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bayesian Logistic Regression</td>\n",
       "      <td>0.8650</td>\n",
       "      <td>0.8607</td>\n",
       "      <td>0.8625</td>\n",
       "      <td>0.9292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.9809</td>\n",
       "      <td>0.9908</td>\n",
       "      <td>0.9858</td>\n",
       "      <td>0.9990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Gradient Boosting</td>\n",
       "      <td>0.9889</td>\n",
       "      <td>0.9949</td>\n",
       "      <td>0.9919</td>\n",
       "      <td>0.9991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.9630</td>\n",
       "      <td>0.9756</td>\n",
       "      <td>0.9692</td>\n",
       "      <td>0.9694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SVM</td>\n",
       "      <td>0.8799</td>\n",
       "      <td>0.8760</td>\n",
       "      <td>0.8779</td>\n",
       "      <td>0.9439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.9909</td>\n",
       "      <td>0.9929</td>\n",
       "      <td>0.9919</td>\n",
       "      <td>0.9993</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Model  Precision  Recall  F1-Score  ROC AUC\n",
       "0  Bayesian Logistic Regression     0.8650  0.8607    0.8625   0.9292\n",
       "1                 Random Forest     0.9809  0.9908    0.9858   0.9990\n",
       "2             Gradient Boosting     0.9889  0.9949    0.9919   0.9991\n",
       "3                 Decision Tree     0.9630  0.9756    0.9692   0.9694\n",
       "4                           SVM     0.8799  0.8760    0.8779   0.9439\n",
       "5                       XGBoost     0.9909  0.9929    0.9919   0.9993"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_results_df.head(10)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpretation of Test Set Results\n",
    "\n",
    "1. XGBoost (0.9991 ROC AUC, 0.9816 F1-Score)\n",
    "+ Maintains excellent performance on the test set, with a very high ROC AUC and F1-Score.\n",
    "+ This indicates strong generalization ability, meaning it's likely to perform well on new, unseen data.\n",
    "\n",
    "2. Gradient Boosting (0.9989 ROC AUC, 0.9857 F1-Score)\n",
    "+ Also shows outstanding performance on the test set, comparable to XGBoost.\n",
    "+ Achieves a slightly higher F1-Score than XGBoost, indicating a marginally better balance of precision and recall.\n",
    "\n",
    "3. Random Forest (0.9989 ROC AUC, 0.9837 F1-Score)\n",
    "+ Performs very well on the test set, with a high ROC AUC and F1-Score.\n",
    "+ While slightly behind XGBoost and Gradient Boosting, it's still a strong model.\n",
    "\n",
    "**Observations**\n",
    "\n",
    "All three models generalize well to the test set, confirming their strong performance observed during training and validation.\n",
    "Gradient Boosting has a slight edge in F1-Score on the test set, suggesting a better balance of precision and recall compared to XGBoost.\n",
    "The performance differences between the models are relatively small, indicating that all three are good candidates for deployment.\n",
    "\n",
    "**Recommendations**\n",
    "\n",
    "Model Selection:\n",
    "\n",
    "Our primary focus in selecting a predictive model is maximizing accuracy in identifying potential machine downtime. While computational efficiency and interpretability are valuable,  the ability to proactively prevent downtime is paramount.\n",
    "\n",
    "In this regard, Gradient Boosting emerged as the top performer, achieving the highest F1-score among the models evaluated. This signifies its superior balance between precision (minimizing false alarms) and recall (capturing the majority of actual downtime events).\n",
    "\n",
    "Therefore, we will be deploying Gradient Boosting as our predictive model to proactively mitigate machine downtime and enhance operational efficiency.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1-Score</th>\n",
       "      <th>ROC AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.9877</td>\n",
       "      <td>0.9756</td>\n",
       "      <td>0.9816</td>\n",
       "      <td>0.9991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Gradient Boosting</td>\n",
       "      <td>0.9918</td>\n",
       "      <td>0.9797</td>\n",
       "      <td>0.9857</td>\n",
       "      <td>0.9989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.9837</td>\n",
       "      <td>0.9837</td>\n",
       "      <td>0.9837</td>\n",
       "      <td>0.9989</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Model  Precision  Recall  F1-Score  ROC AUC\n",
       "0            XGBoost     0.9877  0.9756    0.9816   0.9991\n",
       "1  Gradient Boosting     0.9918  0.9797    0.9857   0.9989\n",
       "2      Random Forest     0.9837  0.9837    0.9837   0.9989"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Select top 3 models\n",
    "final_models = {\n",
    "    \"XGBoost\": xgb.XGBClassifier( eval_metric=\"auc\", random_state=42),\n",
    "    \"Random Forest\": RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "    \"Gradient Boosting\": GradientBoostingClassifier(n_estimators=100, random_state=42)\n",
    "}\n",
    "\n",
    "# Store test set evaluation results\n",
    "test_results = []\n",
    "\n",
    "for name, model in final_models.items():\n",
    "    # Create a pipeline\n",
    "    pipeline = Pipeline([\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('classifier', model)\n",
    "    ])\n",
    "\n",
    "    # Train on full train + validation set\n",
    "    pipeline.fit(X_train_val, y_train_val)\n",
    "\n",
    "    # Make predictions on the test set\n",
    "    y_test_pred = pipeline.predict(X_test)\n",
    "    y_test_prob = pipeline.predict_proba(X_test)[:, 1] if hasattr(model, 'predict_proba') else None\n",
    "\n",
    "    # Evaluate model\n",
    "    test_precision = precision_score(y_test, y_test_pred)\n",
    "    test_recall = recall_score(y_test, y_test_pred)\n",
    "    test_f1 = f1_score(y_test, y_test_pred)\n",
    "    test_roc_auc = roc_auc_score(y_test, y_test_prob) if y_test_prob is not None else 'N/A'\n",
    "\n",
    "    # Store results\n",
    "    test_results.append({\n",
    "        \"Model\": name,\n",
    "        \"Precision\": round(test_precision, 4),\n",
    "        \"Recall\": round(test_recall, 4),\n",
    "        \"F1-Score\": round(test_f1, 4),\n",
    "        \"ROC AUC\": round(test_roc_auc, 4) if test_roc_auc != \"N/A\" else \"N/A\"\n",
    "    })\n",
    "    \n",
    "\n",
    "test_results_df = pd.DataFrame(test_results)\n",
    "test_results_df.sort_values(by = ['ROC AUC', 'F1-Score'], ascending= False).reset_index(drop = True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check for Class Imbalance\n",
    "\n",
    "I have trained all the models involved, and most of them exhibit exceptionally high evaluation metric values, reaching as high as 0.99. Given that this is a classification problem, one potential concern could be class imbalance, which often leads to inflated performance metrics. However, after thoroughly checking the class distribution, there doesn’t appear to be any significant imbalance. This suggests that the models might either be capturing strong patterns in the data or potentially overfitting. Further investigation, such as cross-validation performance consistency and feature importance analysis will be implemented to ensure the models’ generalizability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "machine_ori['Downtime'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-02 11:48:00,969] A new study created in memory with name: no-name-013d4ca7-419d-4dc8-94af-1ec209853c8a\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_11688\\4092580619.py:31: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
      "[I 2025-03-02 11:48:01,482] Trial 0 finished with value: 0.990883179169207 and parameters: {'n_estimators': 150, 'max_depth': 11, 'learning_rate': 0.0823928379819445, 'subsample': 0.9340845522751516, 'colsample_bytree': 0.7980668641329671, 'gamma': 1.9301349437406412, 'reg_alpha': 0.5252787676569837, 'reg_lambda': 3.651531919770652}. Best is trial 0 with value: 0.990883179169207.\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_11688\\4092580619.py:31: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
      "[I 2025-03-02 11:48:02,319] Trial 1 finished with value: 0.9893876583589989 and parameters: {'n_estimators': 500, 'max_depth': 10, 'learning_rate': 0.09255853762505925, 'subsample': 0.8414483598404598, 'colsample_bytree': 0.6864808599521643, 'gamma': 1.9878819473956677, 'reg_alpha': 3.0500419549720204, 'reg_lambda': 2.2659008385700217}. Best is trial 0 with value: 0.990883179169207.\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_11688\\4092580619.py:31: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
      "[I 2025-03-02 11:48:02,927] Trial 2 finished with value: 0.9872502267529268 and parameters: {'n_estimators': 300, 'max_depth': 9, 'learning_rate': 0.036157260078159725, 'subsample': 0.7358739178840874, 'colsample_bytree': 0.7999480754288982, 'gamma': 4.96993795149073, 'reg_alpha': 7.543294811534142, 'reg_lambda': 6.132434659111103}. Best is trial 0 with value: 0.990883179169207.\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_11688\\4092580619.py:31: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
      "[I 2025-03-02 11:48:03,453] Trial 3 finished with value: 0.9871963144842202 and parameters: {'n_estimators': 250, 'max_depth': 6, 'learning_rate': 0.07844859611514307, 'subsample': 0.9315144914218415, 'colsample_bytree': 0.8768651618027393, 'gamma': 7.536622812697852, 'reg_alpha': 6.149979999019772, 'reg_lambda': 2.3692279011664787}. Best is trial 0 with value: 0.990883179169207.\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_11688\\4092580619.py:31: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
      "[I 2025-03-02 11:48:03,911] Trial 4 finished with value: 0.9857519359131761 and parameters: {'n_estimators': 100, 'max_depth': 4, 'learning_rate': 0.028080133218888772, 'subsample': 0.6435090373508994, 'colsample_bytree': 0.946414922803932, 'gamma': 6.043488085517749, 'reg_alpha': 5.127066959366853, 'reg_lambda': 0.19027071060985445}. Best is trial 0 with value: 0.990883179169207.\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_11688\\4092580619.py:31: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
      "[I 2025-03-02 11:48:04,291] Trial 5 finished with value: 0.9856720320513606 and parameters: {'n_estimators': 100, 'max_depth': 11, 'learning_rate': 0.06884931035866064, 'subsample': 0.6222419799969662, 'colsample_bytree': 0.9761245429343065, 'gamma': 9.390391927692281, 'reg_alpha': 4.054825432563398, 'reg_lambda': 2.420152474803272}. Best is trial 0 with value: 0.990883179169207.\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_11688\\4092580619.py:31: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
      "[I 2025-03-02 11:48:05,374] Trial 6 finished with value: 0.9889456516003152 and parameters: {'n_estimators': 450, 'max_depth': 12, 'learning_rate': 0.01576229695589044, 'subsample': 0.7185988220488085, 'colsample_bytree': 0.7045202805477047, 'gamma': 0.9525378395002249, 'reg_alpha': 6.69791321058884, 'reg_lambda': 5.378479990737382}. Best is trial 0 with value: 0.990883179169207.\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_11688\\4092580619.py:31: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
      "[I 2025-03-02 11:48:05,916] Trial 7 finished with value: 0.9856552877277809 and parameters: {'n_estimators': 150, 'max_depth': 6, 'learning_rate': 0.013175502197146508, 'subsample': 0.6543517846027502, 'colsample_bytree': 0.6702672838614754, 'gamma': 9.015974392815082, 'reg_alpha': 4.1485707297297, 'reg_lambda': 5.380993918694164}. Best is trial 0 with value: 0.990883179169207.\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_11688\\4092580619.py:31: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
      "[I 2025-03-02 11:48:06,715] Trial 8 finished with value: 0.9894338449473071 and parameters: {'n_estimators': 350, 'max_depth': 3, 'learning_rate': 0.015611158774522429, 'subsample': 0.7432869424219937, 'colsample_bytree': 0.6231514475115784, 'gamma': 1.1769467600569183, 'reg_alpha': 6.684198137985544, 'reg_lambda': 1.3032508184091007}. Best is trial 0 with value: 0.990883179169207.\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_11688\\4092580619.py:31: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
      "[I 2025-03-02 11:48:07,307] Trial 9 finished with value: 0.9883099128044796 and parameters: {'n_estimators': 250, 'max_depth': 11, 'learning_rate': 0.051764426786417204, 'subsample': 0.8498898077169857, 'colsample_bytree': 0.8690689624691061, 'gamma': 4.5031147200463195, 'reg_alpha': 4.144885199116643, 'reg_lambda': 9.577884339976098}. Best is trial 0 with value: 0.990883179169207.\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_11688\\4092580619.py:31: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
      "[I 2025-03-02 11:48:07,858] Trial 10 finished with value: 0.9893296920993726 and parameters: {'n_estimators': 200, 'max_depth': 8, 'learning_rate': 0.23802115703362675, 'subsample': 0.9931081113485203, 'colsample_bytree': 0.7760749006951173, 'gamma': 2.904798614510771, 'reg_alpha': 0.37458867992458067, 'reg_lambda': 7.937425350833598}. Best is trial 0 with value: 0.990883179169207.\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_11688\\4092580619.py:31: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
      "[I 2025-03-02 11:48:08,548] Trial 11 finished with value: 0.9898462108567513 and parameters: {'n_estimators': 350, 'max_depth': 3, 'learning_rate': 0.19896729702456642, 'subsample': 0.7737482756833991, 'colsample_bytree': 0.6086070651312573, 'gamma': 0.09365859068984439, 'reg_alpha': 9.65038583768124, 'reg_lambda': 0.22039761241851208}. Best is trial 0 with value: 0.990883179169207.\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_11688\\4092580619.py:31: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
      "[I 2025-03-02 11:48:09,212] Trial 12 finished with value: 0.9898079800999775 and parameters: {'n_estimators': 400, 'max_depth': 6, 'learning_rate': 0.1893882721591937, 'subsample': 0.8998920748187507, 'colsample_bytree': 0.7449560349441269, 'gamma': 0.17547019329087377, 'reg_alpha': 9.617675591799342, 'reg_lambda': 3.6772204326487556}. Best is trial 0 with value: 0.990883179169207.\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_11688\\4092580619.py:31: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
      "[I 2025-03-02 11:48:10,019] Trial 13 finished with value: 0.9913465108643548 and parameters: {'n_estimators': 350, 'max_depth': 4, 'learning_rate': 0.12917368132623466, 'subsample': 0.7963306369133165, 'colsample_bytree': 0.6235333282652662, 'gamma': 3.2659471702026233, 'reg_alpha': 0.3519825499869551, 'reg_lambda': 0.264608589279911}. Best is trial 13 with value: 0.9913465108643548.\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_11688\\4092580619.py:31: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
      "[I 2025-03-02 11:48:10,649] Trial 14 finished with value: 0.9903669017807744 and parameters: {'n_estimators': 200, 'max_depth': 5, 'learning_rate': 0.11624147998835127, 'subsample': 0.8223726988346276, 'colsample_bytree': 0.844065936313737, 'gamma': 2.8873450542252646, 'reg_alpha': 0.14238055204069577, 'reg_lambda': 3.9812495362271907}. Best is trial 13 with value: 0.9913465108643548.\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_11688\\4092580619.py:31: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
      "[I 2025-03-02 11:48:11,446] Trial 15 finished with value: 0.988316339933492 and parameters: {'n_estimators': 350, 'max_depth': 7, 'learning_rate': 0.12736449545184583, 'subsample': 0.8998956313509126, 'colsample_bytree': 0.9170332626838872, 'gamma': 3.5427674202090866, 'reg_alpha': 1.8991619972420515, 'reg_lambda': 3.8809488678277217}. Best is trial 13 with value: 0.9913465108643548.\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_11688\\4092580619.py:31: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
      "[I 2025-03-02 11:48:12,142] Trial 16 finished with value: 0.986711339664061 and parameters: {'n_estimators': 250, 'max_depth': 8, 'learning_rate': 0.2965729518713764, 'subsample': 0.9995005742242389, 'colsample_bytree': 0.7240577384167801, 'gamma': 6.539468672693761, 'reg_alpha': 1.7543126839531387, 'reg_lambda': 7.141093115754491}. Best is trial 13 with value: 0.9913465108643548.\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_11688\\4092580619.py:31: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
      "[I 2025-03-02 11:48:12,927] Trial 17 finished with value: 0.9889185135906515 and parameters: {'n_estimators': 450, 'max_depth': 9, 'learning_rate': 0.1338305285163642, 'subsample': 0.941326617156399, 'colsample_bytree': 0.6553176245512955, 'gamma': 3.8144659020492098, 'reg_alpha': 1.5503171028880915, 'reg_lambda': 1.3015350946729562}. Best is trial 13 with value: 0.9913465108643548.\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_11688\\4092580619.py:31: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
      "[I 2025-03-02 11:48:13,501] Trial 18 finished with value: 0.9898867624788737 and parameters: {'n_estimators': 150, 'max_depth': 12, 'learning_rate': 0.047520408276011804, 'subsample': 0.7872107445956685, 'colsample_bytree': 0.7628002802415867, 'gamma': 1.4909847129953424, 'reg_alpha': 2.6611074617058748, 'reg_lambda': 3.297725099289197}. Best is trial 13 with value: 0.9913465108643548.\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_11688\\4092580619.py:31: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
      "[I 2025-03-02 11:48:14,294] Trial 19 finished with value: 0.9903160985480478 and parameters: {'n_estimators': 300, 'max_depth': 4, 'learning_rate': 0.024003853005463222, 'subsample': 0.8810325670487381, 'colsample_bytree': 0.8213044363223663, 'gamma': 2.3807222613476764, 'reg_alpha': 0.9651359002842638, 'reg_lambda': 1.1481503326567268}. Best is trial 13 with value: 0.9913465108643548.\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_11688\\4092580619.py:31: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
      "[I 2025-03-02 11:48:14,881] Trial 20 finished with value: 0.9877047510937345 and parameters: {'n_estimators': 200, 'max_depth': 10, 'learning_rate': 0.1657544384980238, 'subsample': 0.6860883003917413, 'colsample_bytree': 0.6379373955662733, 'gamma': 6.053677549229808, 'reg_alpha': 2.967048317464523, 'reg_lambda': 9.996276903352925}. Best is trial 13 with value: 0.9913465108643548.\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_11688\\4092580619.py:31: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
      "[I 2025-03-02 11:48:15,396] Trial 21 finished with value: 0.9888383994283101 and parameters: {'n_estimators': 150, 'max_depth': 5, 'learning_rate': 0.11135722627508332, 'subsample': 0.8231131145652294, 'colsample_bytree': 0.8447698738701103, 'gamma': 2.966869556771675, 'reg_alpha': 0.2420232509398778, 'reg_lambda': 4.076948903909019}. Best is trial 13 with value: 0.9913465108643548.\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_11688\\4092580619.py:31: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
      "[I 2025-03-02 11:48:16,104] Trial 22 finished with value: 0.9893682423157847 and parameters: {'n_estimators': 200, 'max_depth': 5, 'learning_rate': 0.06912072151486771, 'subsample': 0.807506424088068, 'colsample_bytree': 0.8990129291326383, 'gamma': 3.776430956781453, 'reg_alpha': 0.0639688558846857, 'reg_lambda': 4.579855956007551}. Best is trial 13 with value: 0.9913465108643548.\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_11688\\4092580619.py:31: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
      "[I 2025-03-02 11:48:16,575] Trial 23 finished with value: 0.9908392373707818 and parameters: {'n_estimators': 100, 'max_depth': 4, 'learning_rate': 0.11339328040759279, 'subsample': 0.951170392679826, 'colsample_bytree': 0.7958231231621768, 'gamma': 2.4059481405149614, 'reg_alpha': 1.1279790790723543, 'reg_lambda': 6.434606668677946}. Best is trial 13 with value: 0.9913465108643548.\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_11688\\4092580619.py:31: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
      "[I 2025-03-02 11:48:17,128] Trial 24 finished with value: 0.9893354923702139 and parameters: {'n_estimators': 100, 'max_depth': 4, 'learning_rate': 0.08982761141433021, 'subsample': 0.9568406428934949, 'colsample_bytree': 0.8045750429297476, 'gamma': 2.075333468825884, 'reg_alpha': 1.3045398147120624, 'reg_lambda': 6.759842820485364}. Best is trial 13 with value: 0.9913465108643548.\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_11688\\4092580619.py:31: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
      "[I 2025-03-02 11:48:17,564] Trial 25 finished with value: 0.9883570460304207 and parameters: {'n_estimators': 150, 'max_depth': 7, 'learning_rate': 0.1521678857235459, 'subsample': 0.8725779371111954, 'colsample_bytree': 0.7361917350889313, 'gamma': 4.4314281747207005, 'reg_alpha': 2.354353953397154, 'reg_lambda': 8.22972775495268}. Best is trial 13 with value: 0.9913465108643548.\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_11688\\4092580619.py:31: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
      "[I 2025-03-02 11:48:18,395] Trial 26 finished with value: 0.9924311184570982 and parameters: {'n_estimators': 400, 'max_depth': 3, 'learning_rate': 0.05606629587417093, 'subsample': 0.9700621520063809, 'colsample_bytree': 0.7787772764287041, 'gamma': 0.7609994850789783, 'reg_alpha': 0.9468814473962791, 'reg_lambda': 6.144908382870932}. Best is trial 26 with value: 0.9924311184570982.\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_11688\\4092580619.py:31: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
      "[I 2025-03-02 11:48:19,251] Trial 27 finished with value: 0.9913667306649432 and parameters: {'n_estimators': 400, 'max_depth': 3, 'learning_rate': 0.03608874578971901, 'subsample': 0.9763890090195605, 'colsample_bytree': 0.9986929467189567, 'gamma': 0.6432347450891079, 'reg_alpha': 0.9224043588431138, 'reg_lambda': 4.972726938038544}. Best is trial 26 with value: 0.9924311184570982.\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_11688\\4092580619.py:31: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
      "[I 2025-03-02 11:48:20,075] Trial 28 finished with value: 0.9892892070361973 and parameters: {'n_estimators': 400, 'max_depth': 3, 'learning_rate': 0.0333859495500489, 'subsample': 0.9663898347194219, 'colsample_bytree': 0.9840273589950632, 'gamma': 0.8277672190153307, 'reg_alpha': 3.546507350859789, 'reg_lambda': 7.758447211074843}. Best is trial 26 with value: 0.9924311184570982.\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_11688\\4092580619.py:31: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
      "[I 2025-03-02 11:48:21,062] Trial 29 finished with value: 0.9893522716212582 and parameters: {'n_estimators': 400, 'max_depth': 3, 'learning_rate': 0.021089410831638997, 'subsample': 0.908115566016904, 'colsample_bytree': 0.9296450041898661, 'gamma': 0.6335304887583936, 'reg_alpha': 2.1752572067935967, 'reg_lambda': 9.128752754447275}. Best is trial 26 with value: 0.9924311184570982.\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_11688\\4092580619.py:31: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
      "[I 2025-03-02 11:48:21,933] Trial 30 finished with value: 0.9909293743384022 and parameters: {'n_estimators': 450, 'max_depth': 4, 'learning_rate': 0.040094457930096764, 'subsample': 0.7591028113104092, 'colsample_bytree': 0.7076741908419334, 'gamma': 1.5774825487648085, 'reg_alpha': 0.8197604479169222, 'reg_lambda': 5.820861777587742}. Best is trial 26 with value: 0.9924311184570982.\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_11688\\4092580619.py:31: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
      "[I 2025-03-02 11:48:22,791] Trial 31 finished with value: 0.9909226023616682 and parameters: {'n_estimators': 450, 'max_depth': 4, 'learning_rate': 0.0413720477869024, 'subsample': 0.7620654782078571, 'colsample_bytree': 0.6996009657521742, 'gamma': 1.634611708986718, 'reg_alpha': 0.8398241335383885, 'reg_lambda': 5.5053450849277015}. Best is trial 26 with value: 0.9924311184570982.\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_11688\\4092580619.py:31: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
      "[I 2025-03-02 11:48:23,587] Trial 32 finished with value: 0.9899456242152405 and parameters: {'n_estimators': 500, 'max_depth': 3, 'learning_rate': 0.06217065154821565, 'subsample': 0.701803896692411, 'colsample_bytree': 0.6666508459866803, 'gamma': 1.6617747325841399, 'reg_alpha': 0.8595070609016222, 'reg_lambda': 4.801706579946259}. Best is trial 26 with value: 0.9924311184570982.\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_11688\\4092580619.py:31: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
      "[I 2025-03-02 11:48:24,533] Trial 33 finished with value: 0.9908899076168058 and parameters: {'n_estimators': 400, 'max_depth': 5, 'learning_rate': 0.031729211488302746, 'subsample': 0.9779304506810174, 'colsample_bytree': 0.7169343777186936, 'gamma': 0.7102495511980429, 'reg_alpha': 1.5963499424072176, 'reg_lambda': 5.927100734366021}. Best is trial 26 with value: 0.9924311184570982.\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_11688\\4092580619.py:31: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
      "[I 2025-03-02 11:48:25,442] Trial 34 finished with value: 0.9908719048187651 and parameters: {'n_estimators': 450, 'max_depth': 4, 'learning_rate': 0.039178636286557406, 'subsample': 0.8470277288766175, 'colsample_bytree': 0.7631312552015467, 'gamma': 0.199245215813734, 'reg_alpha': 3.27044923254396, 'reg_lambda': 2.9819072607520947}. Best is trial 26 with value: 0.9924311184570982.\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_11688\\4092580619.py:31: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
      "[I 2025-03-02 11:48:26,244] Trial 35 finished with value: 0.9904643159058549 and parameters: {'n_estimators': 350, 'max_depth': 3, 'learning_rate': 0.02386082995304079, 'subsample': 0.924368694482697, 'colsample_bytree': 0.6021806885972903, 'gamma': 1.9866566118176576, 'reg_alpha': 0.7004710499290335, 'reg_lambda': 7.039855343380281}. Best is trial 26 with value: 0.9924311184570982.\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_11688\\4092580619.py:31: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
      "[I 2025-03-02 11:48:27,567] Trial 36 finished with value: 0.9889276935490081 and parameters: {'n_estimators': 500, 'max_depth': 5, 'learning_rate': 0.010008645717644355, 'subsample': 0.7545526703301539, 'colsample_bytree': 0.6836389742002025, 'gamma': 1.2793921292083599, 'reg_alpha': 5.453767770082575, 'reg_lambda': 8.626595091221755}. Best is trial 26 with value: 0.9924311184570982.\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_11688\\4092580619.py:31: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
      "[I 2025-03-02 11:48:28,252] Trial 37 finished with value: 0.9883188347552179 and parameters: {'n_estimators': 400, 'max_depth': 4, 'learning_rate': 0.05667275634168518, 'subsample': 0.7990863447123062, 'colsample_bytree': 0.6371173112430348, 'gamma': 3.2097400457990117, 'reg_alpha': 7.93317489590078, 'reg_lambda': 5.986608422471586}. Best is trial 26 with value: 0.9924311184570982.\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_11688\\4092580619.py:31: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
      "[I 2025-03-02 11:48:29,060] Trial 38 finished with value: 0.9893152202735463 and parameters: {'n_estimators': 500, 'max_depth': 6, 'learning_rate': 0.08205383806484597, 'subsample': 0.8677425376809886, 'colsample_bytree': 0.9650017234909268, 'gamma': 2.4403539620944783, 'reg_alpha': 2.414661972772049, 'reg_lambda': 4.551666052118071}. Best is trial 26 with value: 0.9924311184570982.\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_11688\\4092580619.py:31: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
      "[I 2025-03-02 11:48:29,722] Trial 39 finished with value: 0.9883886411814576 and parameters: {'n_estimators': 350, 'max_depth': 3, 'learning_rate': 0.04277247016531867, 'subsample': 0.7263516378027804, 'colsample_bytree': 0.696639603667479, 'gamma': 5.252515564516377, 'reg_alpha': 1.2311730769949003, 'reg_lambda': 7.549554264825757}. Best is trial 26 with value: 0.9924311184570982.\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_11688\\4092580619.py:31: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
      "[I 2025-03-02 11:48:30,492] Trial 40 finished with value: 0.9893429698982659 and parameters: {'n_estimators': 450, 'max_depth': 5, 'learning_rate': 0.07158993057160182, 'subsample': 0.673307454370769, 'colsample_bytree': 0.8342432737273424, 'gamma': 0.5829353066733653, 'reg_alpha': 3.554748723360826, 'reg_lambda': 2.076289827847155}. Best is trial 26 with value: 0.9924311184570982.\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_11688\\4092580619.py:31: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
      "[I 2025-03-02 11:48:31,313] Trial 41 finished with value: 0.9909068362915028 and parameters: {'n_estimators': 450, 'max_depth': 4, 'learning_rate': 0.04466656754873043, 'subsample': 0.7607599007205753, 'colsample_bytree': 0.7061584045801242, 'gamma': 1.7503156519670904, 'reg_alpha': 0.6526902713325904, 'reg_lambda': 5.71100662308449}. Best is trial 26 with value: 0.9924311184570982.\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_11688\\4092580619.py:31: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
      "[I 2025-03-02 11:48:32,268] Trial 42 finished with value: 0.9914345328385817 and parameters: {'n_estimators': 450, 'max_depth': 4, 'learning_rate': 0.02788787296403525, 'subsample': 0.7710667678602845, 'colsample_bytree': 0.6850393121464996, 'gamma': 1.3040602282574494, 'reg_alpha': 0.5308763437339961, 'reg_lambda': 5.331617319640465}. Best is trial 26 with value: 0.9924311184570982.\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_11688\\4092580619.py:31: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
      "[I 2025-03-02 11:48:33,163] Trial 43 finished with value: 0.9894677405200544 and parameters: {'n_estimators': 400, 'max_depth': 3, 'learning_rate': 0.02675302404264982, 'subsample': 0.783294506382028, 'colsample_bytree': 0.6507475313484753, 'gamma': 1.0801258402405776, 'reg_alpha': 2.0054594603552904, 'reg_lambda': 6.424175059955338}. Best is trial 26 with value: 0.9924311184570982.\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_11688\\4092580619.py:31: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
      "[I 2025-03-02 11:48:33,960] Trial 44 finished with value: 0.9883774060985575 and parameters: {'n_estimators': 350, 'max_depth': 4, 'learning_rate': 0.016911928027281854, 'subsample': 0.7446342304549807, 'colsample_bytree': 0.6793071232543212, 'gamma': 7.974094984563308, 'reg_alpha': 0.6133498853084938, 'reg_lambda': 5.302930998521545}. Best is trial 26 with value: 0.9924311184570982.\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_11688\\4092580619.py:31: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
      "[I 2025-03-02 11:48:34,794] Trial 45 finished with value: 0.9899716993284126 and parameters: {'n_estimators': 450, 'max_depth': 3, 'learning_rate': 0.0301401250201416, 'subsample': 0.7100333736093057, 'colsample_bytree': 0.6313472694228051, 'gamma': 1.289771964178253, 'reg_alpha': 1.3637846083896294, 'reg_lambda': 5.224203329669141}. Best is trial 26 with value: 0.9924311184570982.\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_11688\\4092580619.py:31: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
      "[I 2025-03-02 11:48:35,868] Trial 46 finished with value: 0.9924242684248143 and parameters: {'n_estimators': 300, 'max_depth': 6, 'learning_rate': 0.03634142096866674, 'subsample': 0.8180496131814736, 'colsample_bytree': 0.9985861242570616, 'gamma': 0.03241823401599164, 'reg_alpha': 0.1936904512868587, 'reg_lambda': 4.329997320336852}. Best is trial 26 with value: 0.9924311184570982.\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_11688\\4092580619.py:31: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
      "[I 2025-03-02 11:48:37,026] Trial 47 finished with value: 0.990344463044775 and parameters: {'n_estimators': 300, 'max_depth': 7, 'learning_rate': 0.017721265081948896, 'subsample': 0.6129226124908689, 'colsample_bytree': 0.9518388221603512, 'gamma': 0.12599514917856136, 'reg_alpha': 0.43297987648888114, 'reg_lambda': 2.9263989391182337}. Best is trial 26 with value: 0.9924311184570982.\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_11688\\4092580619.py:31: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
      "[I 2025-03-02 11:48:38,112] Trial 48 finished with value: 0.9928960190209988 and parameters: {'n_estimators': 300, 'max_depth': 6, 'learning_rate': 0.035264388109062864, 'subsample': 0.8330933949030837, 'colsample_bytree': 0.9979899230209462, 'gamma': 0.01554216754804006, 'reg_alpha': 0.06777571507812014, 'reg_lambda': 4.312297528538607}. Best is trial 48 with value: 0.9928960190209988.\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_11688\\4092580619.py:31: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
      "[I 2025-03-02 11:48:39,074] Trial 49 finished with value: 0.9903476739137396 and parameters: {'n_estimators': 250, 'max_depth': 6, 'learning_rate': 0.03519889361079924, 'subsample': 0.8264277697468903, 'colsample_bytree': 0.9995597125289067, 'gamma': 0.002605221925925367, 'reg_alpha': 4.644897218374692, 'reg_lambda': 4.280979143337501}. Best is trial 48 with value: 0.9928960190209988.\n",
      "[I 2025-03-02 11:48:39,075] A new study created in memory with name: no-name-1401990a-ccc2-4c77-a7ac-f40bb16e6849\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_11688\\4092580619.py:47: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
      "[I 2025-03-02 11:48:48,606] Trial 0 finished with value: 0.9860978628399946 and parameters: {'n_estimators': 250, 'learning_rate': 0.015056358838452258, 'max_depth': 4, 'subsample': 0.7367664431420533}. Best is trial 0 with value: 0.9860978628399946.\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_11688\\4092580619.py:47: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
      "[I 2025-03-02 11:49:26,124] Trial 1 finished with value: 0.9826488353456719 and parameters: {'n_estimators': 300, 'learning_rate': 0.010907266704743412, 'max_depth': 11, 'subsample': 0.8696632194269742}. Best is trial 0 with value: 0.9860978628399946.\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_11688\\4092580619.py:47: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
      "[I 2025-03-02 11:49:43,393] Trial 2 finished with value: 0.9913788516795535 and parameters: {'n_estimators': 400, 'learning_rate': 0.11641755716118223, 'max_depth': 8, 'subsample': 0.7182307417038702}. Best is trial 2 with value: 0.9913788516795535.\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_11688\\4092580619.py:47: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
      "[I 2025-03-02 11:49:57,201] Trial 3 finished with value: 0.9918440230241279 and parameters: {'n_estimators': 250, 'learning_rate': 0.15081270846148984, 'max_depth': 9, 'subsample': 0.8160916610323513}. Best is trial 3 with value: 0.9918440230241279.\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_11688\\4092580619.py:47: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
      "[I 2025-03-02 11:50:37,257] Trial 4 finished with value: 0.9887449699206472 and parameters: {'n_estimators': 350, 'learning_rate': 0.03625132109591125, 'max_depth': 11, 'subsample': 0.8048962979304802}. Best is trial 3 with value: 0.9918440230241279.\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_11688\\4092580619.py:47: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
      "[I 2025-03-02 11:51:08,293] Trial 5 finished with value: 0.9840916393136568 and parameters: {'n_estimators': 250, 'learning_rate': 0.020732836264525635, 'max_depth': 12, 'subsample': 0.833800792929555}. Best is trial 3 with value: 0.9918440230241279.\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_11688\\4092580619.py:47: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
      "[I 2025-03-02 11:51:17,035] Trial 6 finished with value: 0.9929206627865448 and parameters: {'n_estimators': 300, 'learning_rate': 0.233148975327117, 'max_depth': 7, 'subsample': 0.8704058837684745}. Best is trial 6 with value: 0.9929206627865448.\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_11688\\4092580619.py:47: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
      "[I 2025-03-02 11:51:36,472] Trial 7 finished with value: 0.9923402038684518 and parameters: {'n_estimators': 450, 'learning_rate': 0.01998671790859148, 'max_depth': 4, 'subsample': 0.9756383371188228}. Best is trial 6 with value: 0.9929206627865448.\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_11688\\4092580619.py:47: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
      "[I 2025-03-02 11:51:56,441] Trial 8 finished with value: 0.9849690172004862 and parameters: {'n_estimators': 200, 'learning_rate': 0.01955953695452993, 'max_depth': 10, 'subsample': 0.7816811187329318}. Best is trial 6 with value: 0.9929206627865448.\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_11688\\4092580619.py:47: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
      "[I 2025-03-02 11:53:00,044] Trial 9 finished with value: 0.9809570195173127 and parameters: {'n_estimators': 500, 'learning_rate': 0.012731983578327399, 'max_depth': 11, 'subsample': 0.9181289861219337}. Best is trial 6 with value: 0.9929206627865448.\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_11688\\4092580619.py:47: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
      "[I 2025-03-02 11:53:05,512] Trial 10 finished with value: 0.9934909070001021 and parameters: {'n_estimators': 100, 'learning_rate': 0.2677639894791182, 'max_depth': 6, 'subsample': 0.6472763111272002}. Best is trial 10 with value: 0.9934909070001021.\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_11688\\4092580619.py:47: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
      "[I 2025-03-02 11:53:10,478] Trial 11 finished with value: 0.9919204102239754 and parameters: {'n_estimators': 100, 'learning_rate': 0.2980129877925788, 'max_depth': 6, 'subsample': 0.6104760670275169}. Best is trial 10 with value: 0.9934909070001021.\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_11688\\4092580619.py:47: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
      "[I 2025-03-02 11:53:15,177] Trial 12 finished with value: 0.990941487940158 and parameters: {'n_estimators': 100, 'learning_rate': 0.29834209316928306, 'max_depth': 6, 'subsample': 0.6063883352417467}. Best is trial 10 with value: 0.9934909070001021.\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_11688\\4092580619.py:47: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
      "[I 2025-03-02 11:53:23,210] Trial 13 finished with value: 0.9924466614601057 and parameters: {'n_estimators': 150, 'learning_rate': 0.13355021603236641, 'max_depth': 6, 'subsample': 0.6825131770037511}. Best is trial 10 with value: 0.9934909070001021.\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_11688\\4092580619.py:47: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
      "[I 2025-03-02 11:53:46,452] Trial 14 finished with value: 0.9933840416665549 and parameters: {'n_estimators': 350, 'learning_rate': 0.07335193308651629, 'max_depth': 7, 'subsample': 0.9043866723666429}. Best is trial 10 with value: 0.9934909070001021.\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_11688\\4092580619.py:47: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
      "[I 2025-03-02 11:54:00,034] Trial 15 finished with value: 0.9924714350172823 and parameters: {'n_estimators': 400, 'learning_rate': 0.04581842825602931, 'max_depth': 3, 'subsample': 0.999593860475987}. Best is trial 10 with value: 0.9934909070001021.\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_11688\\4092580619.py:47: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
      "[I 2025-03-02 11:54:22,969] Trial 16 finished with value: 0.9913902302520639 and parameters: {'n_estimators': 350, 'learning_rate': 0.07907172326206777, 'max_depth': 8, 'subsample': 0.9208620902788972}. Best is trial 10 with value: 0.9934909070001021.\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_11688\\4092580619.py:47: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
      "[I 2025-03-02 11:54:29,418] Trial 17 finished with value: 0.9923807447133919 and parameters: {'n_estimators': 150, 'learning_rate': 0.07510986029935615, 'max_depth': 5, 'subsample': 0.6573311448716278}. Best is trial 10 with value: 0.9934909070001021.\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_11688\\4092580619.py:47: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
      "[I 2025-03-02 11:55:03,459] Trial 18 finished with value: 0.9914258982628851 and parameters: {'n_estimators': 500, 'learning_rate': 0.03356022128991269, 'max_depth': 7, 'subsample': 0.7608945836550225}. Best is trial 10 with value: 0.9934909070001021.\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_11688\\4092580619.py:47: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
      "[I 2025-03-02 11:55:16,114] Trial 19 finished with value: 0.990330854211009 and parameters: {'n_estimators': 350, 'learning_rate': 0.17322322181219432, 'max_depth': 9, 'subsample': 0.8946675935942475}. Best is trial 10 with value: 0.9934909070001021.\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_11688\\4092580619.py:47: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
      "[I 2025-03-02 11:55:27,164] Trial 20 finished with value: 0.9934088185721266 and parameters: {'n_estimators': 200, 'learning_rate': 0.0881062655081859, 'max_depth': 5, 'subsample': 0.9565665942284172}. Best is trial 10 with value: 0.9934909070001021.\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_11688\\4092580619.py:47: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
      "[I 2025-03-02 11:55:35,333] Trial 21 finished with value: 0.993334490290608 and parameters: {'n_estimators': 150, 'learning_rate': 0.07168274119661519, 'max_depth': 5, 'subsample': 0.9326939036671158}. Best is trial 10 with value: 0.9934909070001021.\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_11688\\4092580619.py:47: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
      "[I 2025-03-02 11:55:46,384] Trial 22 finished with value: 0.9929274207608998 and parameters: {'n_estimators': 200, 'learning_rate': 0.09951237452267161, 'max_depth': 5, 'subsample': 0.9654837137080702}. Best is trial 10 with value: 0.9934909070001021.\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_11688\\4092580619.py:47: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
      "[I 2025-03-02 11:56:02,983] Trial 23 finished with value: 0.9878802397101903 and parameters: {'n_estimators': 200, 'learning_rate': 0.05664030817730697, 'max_depth': 7, 'subsample': 0.9517872270753198}. Best is trial 10 with value: 0.9934909070001021.\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_11688\\4092580619.py:47: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
      "[I 2025-03-02 11:56:06,731] Trial 24 finished with value: 0.9929789539608191 and parameters: {'n_estimators': 100, 'learning_rate': 0.18380231756819146, 'max_depth': 3, 'subsample': 0.8719823627997645}. Best is trial 10 with value: 0.9934909070001021.\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_11688\\4092580619.py:47: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
      "[I 2025-03-02 11:56:16,626] Trial 25 finished with value: 0.9928981390464241 and parameters: {'n_estimators': 150, 'learning_rate': 0.10646730467242499, 'max_depth': 6, 'subsample': 0.8447432338933505}. Best is trial 10 with value: 0.9934909070001021.\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_11688\\4092580619.py:47: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
      "[I 2025-03-02 11:56:30,986] Trial 26 finished with value: 0.9939366074815339 and parameters: {'n_estimators': 300, 'learning_rate': 0.05399329818850158, 'max_depth': 4, 'subsample': 0.9921848686794377}. Best is trial 26 with value: 0.9939366074815339.\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_11688\\4092580619.py:47: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
      "[I 2025-03-02 11:56:40,202] Trial 27 finished with value: 0.9913049584158664 and parameters: {'n_estimators': 200, 'learning_rate': 0.031065685603266203, 'max_depth': 4, 'subsample': 0.995361847561303}. Best is trial 26 with value: 0.9939366074815339.\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_11688\\4092580619.py:47: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
      "[I 2025-03-02 11:56:51,517] Trial 28 finished with value: 0.9929003912986764 and parameters: {'n_estimators': 250, 'learning_rate': 0.05233106159024654, 'max_depth': 5, 'subsample': 0.6718441595122332}. Best is trial 26 with value: 0.9939366074815339.\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_11688\\4092580619.py:47: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
      "[I 2025-03-02 11:57:01,433] Trial 29 finished with value: 0.9913431451775371 and parameters: {'n_estimators': 300, 'learning_rate': 0.026347458546265225, 'max_depth': 4, 'subsample': 0.7012315594360193}. Best is trial 26 with value: 0.9939366074815339.\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_11688\\4092580619.py:47: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
      "[I 2025-03-02 11:57:08,051] Trial 30 finished with value: 0.9935280838856706 and parameters: {'n_estimators': 250, 'learning_rate': 0.211262954619136, 'max_depth': 3, 'subsample': 0.7439674408896529}. Best is trial 26 with value: 0.9939366074815339.\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_11688\\4092580619.py:47: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
      "[I 2025-03-02 11:57:14,780] Trial 31 finished with value: 0.9935078133110009 and parameters: {'n_estimators': 250, 'learning_rate': 0.2347099629516746, 'max_depth': 3, 'subsample': 0.7631744377203546}. Best is trial 26 with value: 0.9939366074815339.\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_11688\\4092580619.py:47: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
      "[I 2025-03-02 11:57:22,780] Trial 32 finished with value: 0.9940264459646896 and parameters: {'n_estimators': 300, 'learning_rate': 0.2211783998617671, 'max_depth': 3, 'subsample': 0.7562684650920716}. Best is trial 32 with value: 0.9940264459646896.\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_11688\\4092580619.py:47: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
      "[I 2025-03-02 11:57:30,732] Trial 33 finished with value: 0.9940354549736986 and parameters: {'n_estimators': 300, 'learning_rate': 0.21041364508910299, 'max_depth': 3, 'subsample': 0.7479082372280391}. Best is trial 33 with value: 0.9940354549736986.\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_11688\\4092580619.py:47: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
      "[I 2025-03-02 11:57:38,588] Trial 34 finished with value: 0.9940173529003693 and parameters: {'n_estimators': 300, 'learning_rate': 0.19432713670706048, 'max_depth': 3, 'subsample': 0.7330546414985066}. Best is trial 33 with value: 0.9940354549736986.\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_11688\\4092580619.py:47: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
      "[I 2025-03-02 11:57:48,580] Trial 35 finished with value: 0.9930037314751898 and parameters: {'n_estimators': 300, 'learning_rate': 0.1290851760691769, 'max_depth': 4, 'subsample': 0.7145963772537737}. Best is trial 33 with value: 0.9940354549736986.\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_11688\\4092580619.py:47: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
      "[I 2025-03-02 11:57:58,996] Trial 36 finished with value: 0.9944981971696731 and parameters: {'n_estimators': 400, 'learning_rate': 0.1597707170859561, 'max_depth': 3, 'subsample': 0.736778753300394}. Best is trial 36 with value: 0.9944981971696731.\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_11688\\4092580619.py:47: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
      "[I 2025-03-02 11:58:09,487] Trial 37 finished with value: 0.9945314813539532 and parameters: {'n_estimators': 400, 'learning_rate': 0.18237968948364486, 'max_depth': 3, 'subsample': 0.733757648954434}. Best is trial 37 with value: 0.9945314813539532.\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_11688\\4092580619.py:47: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
      "[I 2025-03-02 11:58:20,468] Trial 38 finished with value: 0.9945427429196139 and parameters: {'n_estimators': 400, 'learning_rate': 0.15530861323399475, 'max_depth': 3, 'subsample': 0.7886683462621279}. Best is trial 38 with value: 0.9945427429196139.\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_11688\\4092580619.py:47: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
      "[I 2025-03-02 11:58:32,387] Trial 39 finished with value: 0.9944958605577101 and parameters: {'n_estimators': 400, 'learning_rate': 0.15504378659175327, 'max_depth': 4, 'subsample': 0.789582914530145}. Best is trial 38 with value: 0.9945427429196139.\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_11688\\4092580619.py:47: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
      "[I 2025-03-02 11:58:43,885] Trial 40 finished with value: 0.9940218577092734 and parameters: {'n_estimators': 400, 'learning_rate': 0.16057459897244436, 'max_depth': 4, 'subsample': 0.7904637619508097}. Best is trial 38 with value: 0.9945427429196139.\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_11688\\4092580619.py:47: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
      "[I 2025-03-02 11:58:56,447] Trial 41 finished with value: 0.9940298129680565 and parameters: {'n_estimators': 450, 'learning_rate': 0.143686290656388, 'max_depth': 3, 'subsample': 0.8150578057354638}. Best is trial 38 with value: 0.9945427429196139.\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_11688\\4092580619.py:47: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
      "[I 2025-03-02 11:59:11,266] Trial 42 finished with value: 0.9940241099615257 and parameters: {'n_estimators': 450, 'learning_rate': 0.12606290540335058, 'max_depth': 4, 'subsample': 0.7809604374627566}. Best is trial 38 with value: 0.9945427429196139.\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_11688\\4092580619.py:47: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
      "[I 2025-03-02 11:59:24,485] Trial 43 finished with value: 0.9935258313290188 and parameters: {'n_estimators': 400, 'learning_rate': 0.17444028423228247, 'max_depth': 3, 'subsample': 0.831240334148318}. Best is trial 38 with value: 0.9945427429196139.\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_11688\\4092580619.py:47: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
      "[I 2025-03-02 11:59:35,019] Trial 44 finished with value: 0.9940298132724561 and parameters: {'n_estimators': 450, 'learning_rate': 0.24350843190435198, 'max_depth': 4, 'subsample': 0.7244006357336309}. Best is trial 38 with value: 0.9945427429196139.\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_11688\\4092580619.py:47: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
      "[I 2025-03-02 11:59:48,431] Trial 45 finished with value: 0.9935078130066013 and parameters: {'n_estimators': 400, 'learning_rate': 0.11093089998575235, 'max_depth': 3, 'subsample': 0.7006495787782364}. Best is trial 38 with value: 0.9945427429196139.\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_11688\\4092580619.py:47: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
      "[I 2025-03-02 12:00:00,796] Trial 46 finished with value: 0.9940331189705346 and parameters: {'n_estimators': 350, 'learning_rate': 0.14680385726211392, 'max_depth': 4, 'subsample': 0.8016557397063103}. Best is trial 38 with value: 0.9945427429196139.\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_11688\\4092580619.py:47: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
      "[I 2025-03-02 12:00:14,327] Trial 47 finished with value: 0.9908090538089213 and parameters: {'n_estimators': 400, 'learning_rate': 0.20114078238262834, 'max_depth': 12, 'subsample': 0.7749396612817466}. Best is trial 38 with value: 0.9945427429196139.\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_11688\\4092580619.py:47: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
      "[I 2025-03-02 12:00:23,702] Trial 48 finished with value: 0.9945394833443265 and parameters: {'n_estimators': 500, 'learning_rate': 0.2619416048487702, 'max_depth': 3, 'subsample': 0.7440735742056571}. Best is trial 38 with value: 0.9945427429196139.\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_11688\\4092580619.py:47: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
      "[I 2025-03-02 12:00:32,554] Trial 49 finished with value: 0.9945404906673616 and parameters: {'n_estimators': 500, 'learning_rate': 0.2626266059303878, 'max_depth': 4, 'subsample': 0.709228625874268}. Best is trial 38 with value: 0.9945427429196139.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;preprocessor&#x27;,\n",
       "                 ColumnTransformer(transformers=[(&#x27;robust&#x27;, RobustScaler(),\n",
       "                                                  [&#x27;Coolant_Temperature&#x27;,\n",
       "                                                   &#x27;Torque(Nm)&#x27;,\n",
       "                                                   &#x27;Hydraulic_Pressure(Pa)&#x27;,\n",
       "                                                   &#x27;Cutting(N)&#x27;,\n",
       "                                                   &#x27;Spindle_Speed(RPS)&#x27;]),\n",
       "                                                 (&#x27;standard&#x27;, StandardScaler(),\n",
       "                                                  [&#x27;Hydraulic_Oil_Temperature&#x27;,\n",
       "                                                   &#x27;Spindle_Bearing_Temperature&#x27;,\n",
       "                                                   &#x27;Spindle_Vibration&#x27;,\n",
       "                                                   &#x27;Tool_Vibration&#x27;,\n",
       "                                                   &#x27;Voltage(volts)&#x27;,\n",
       "                                                   &#x27;Coolant_Pressure(Pa)&#x27;...\n",
       "                               grow_policy=None, importance_type=None,\n",
       "                               interaction_constraints=None,\n",
       "                               learning_rate=0.035264388109062864, max_bin=None,\n",
       "                               max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "                               max_delta_step=None, max_depth=6,\n",
       "                               max_leaves=None, min_child_weight=None,\n",
       "                               missing=nan, monotone_constraints=None,\n",
       "                               multi_strategy=None, n_estimators=300,\n",
       "                               n_jobs=None, num_parallel_tree=None,\n",
       "                               random_state=42, ...))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>Pipeline</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.pipeline.Pipeline.html\">?<span>Documentation for Pipeline</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>Pipeline(steps=[(&#x27;preprocessor&#x27;,\n",
       "                 ColumnTransformer(transformers=[(&#x27;robust&#x27;, RobustScaler(),\n",
       "                                                  [&#x27;Coolant_Temperature&#x27;,\n",
       "                                                   &#x27;Torque(Nm)&#x27;,\n",
       "                                                   &#x27;Hydraulic_Pressure(Pa)&#x27;,\n",
       "                                                   &#x27;Cutting(N)&#x27;,\n",
       "                                                   &#x27;Spindle_Speed(RPS)&#x27;]),\n",
       "                                                 (&#x27;standard&#x27;, StandardScaler(),\n",
       "                                                  [&#x27;Hydraulic_Oil_Temperature&#x27;,\n",
       "                                                   &#x27;Spindle_Bearing_Temperature&#x27;,\n",
       "                                                   &#x27;Spindle_Vibration&#x27;,\n",
       "                                                   &#x27;Tool_Vibration&#x27;,\n",
       "                                                   &#x27;Voltage(volts)&#x27;,\n",
       "                                                   &#x27;Coolant_Pressure(Pa)&#x27;...\n",
       "                               grow_policy=None, importance_type=None,\n",
       "                               interaction_constraints=None,\n",
       "                               learning_rate=0.035264388109062864, max_bin=None,\n",
       "                               max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "                               max_delta_step=None, max_depth=6,\n",
       "                               max_leaves=None, min_child_weight=None,\n",
       "                               missing=nan, monotone_constraints=None,\n",
       "                               multi_strategy=None, n_estimators=300,\n",
       "                               n_jobs=None, num_parallel_tree=None,\n",
       "                               random_state=42, ...))])</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>preprocessor: ColumnTransformer</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.compose.ColumnTransformer.html\">?<span>Documentation for preprocessor: ColumnTransformer</span></a></div></label><div class=\"sk-toggleable__content fitted\"><pre>ColumnTransformer(transformers=[(&#x27;robust&#x27;, RobustScaler(),\n",
       "                                 [&#x27;Coolant_Temperature&#x27;, &#x27;Torque(Nm)&#x27;,\n",
       "                                  &#x27;Hydraulic_Pressure(Pa)&#x27;, &#x27;Cutting(N)&#x27;,\n",
       "                                  &#x27;Spindle_Speed(RPS)&#x27;]),\n",
       "                                (&#x27;standard&#x27;, StandardScaler(),\n",
       "                                 [&#x27;Hydraulic_Oil_Temperature&#x27;,\n",
       "                                  &#x27;Spindle_Bearing_Temperature&#x27;,\n",
       "                                  &#x27;Spindle_Vibration&#x27;, &#x27;Tool_Vibration&#x27;,\n",
       "                                  &#x27;Voltage(volts)&#x27;, &#x27;Coolant_Pressure(Pa)&#x27;,\n",
       "                                  &#x27;Air_System_Pressure(Pa)&#x27;]),\n",
       "                                (&#x27;one-hot-encoder&#x27;, OneHotEncoder(),\n",
       "                                 Index([&#x27;Machine_ID&#x27;], dtype=&#x27;object&#x27;))])</pre></div> </div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>robust</div></div></label><div class=\"sk-toggleable__content fitted\"><pre>[&#x27;Coolant_Temperature&#x27;, &#x27;Torque(Nm)&#x27;, &#x27;Hydraulic_Pressure(Pa)&#x27;, &#x27;Cutting(N)&#x27;, &#x27;Spindle_Speed(RPS)&#x27;]</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>RobustScaler</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.preprocessing.RobustScaler.html\">?<span>Documentation for RobustScaler</span></a></div></label><div class=\"sk-toggleable__content fitted\"><pre>RobustScaler()</pre></div> </div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>standard</div></div></label><div class=\"sk-toggleable__content fitted\"><pre>[&#x27;Hydraulic_Oil_Temperature&#x27;, &#x27;Spindle_Bearing_Temperature&#x27;, &#x27;Spindle_Vibration&#x27;, &#x27;Tool_Vibration&#x27;, &#x27;Voltage(volts)&#x27;, &#x27;Coolant_Pressure(Pa)&#x27;, &#x27;Air_System_Pressure(Pa)&#x27;]</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>StandardScaler</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.preprocessing.StandardScaler.html\">?<span>Documentation for StandardScaler</span></a></div></label><div class=\"sk-toggleable__content fitted\"><pre>StandardScaler()</pre></div> </div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>one-hot-encoder</div></div></label><div class=\"sk-toggleable__content fitted\"><pre>Index([&#x27;Machine_ID&#x27;], dtype=&#x27;object&#x27;)</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" ><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>OneHotEncoder</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.preprocessing.OneHotEncoder.html\">?<span>Documentation for OneHotEncoder</span></a></div></label><div class=\"sk-toggleable__content fitted\"><pre>OneHotEncoder()</pre></div> </div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" ><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>XGBClassifier</div></div></label><div class=\"sk-toggleable__content fitted\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=0.9979899230209462, device=None,\n",
       "              early_stopping_rounds=None, enable_categorical=False,\n",
       "              eval_metric=&#x27;auc&#x27;, feature_types=None, gamma=0.01554216754804006,\n",
       "              grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=0.035264388109062864,\n",
       "              max_bin=None, max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=6, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              multi_strategy=None, n_estimators=300, n_jobs=None,\n",
       "              num_parallel_tree=None, random_state=42, ...)</pre></div> </div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('preprocessor',\n",
       "                 ColumnTransformer(transformers=[('robust', RobustScaler(),\n",
       "                                                  ['Coolant_Temperature',\n",
       "                                                   'Torque(Nm)',\n",
       "                                                   'Hydraulic_Pressure(Pa)',\n",
       "                                                   'Cutting(N)',\n",
       "                                                   'Spindle_Speed(RPS)']),\n",
       "                                                 ('standard', StandardScaler(),\n",
       "                                                  ['Hydraulic_Oil_Temperature',\n",
       "                                                   'Spindle_Bearing_Temperature',\n",
       "                                                   'Spindle_Vibration',\n",
       "                                                   'Tool_Vibration',\n",
       "                                                   'Voltage(volts)',\n",
       "                                                   'Coolant_Pressure(Pa)'...\n",
       "                               grow_policy=None, importance_type=None,\n",
       "                               interaction_constraints=None,\n",
       "                               learning_rate=0.035264388109062864, max_bin=None,\n",
       "                               max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "                               max_delta_step=None, max_depth=6,\n",
       "                               max_leaves=None, min_child_weight=None,\n",
       "                               missing=nan, monotone_constraints=None,\n",
       "                               multi_strategy=None, n_estimators=300,\n",
       "                               n_jobs=None, num_parallel_tree=None,\n",
       "                               random_state=42, ...))])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cross-validation function\n",
    "def cross_validate_model(model):\n",
    "    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    f1_scores, precision_scores, recall_scores, roc_auc_scores = [], [], [], []\n",
    "    \n",
    "    for train_idx, val_idx in skf.split(X_train, y_train):\n",
    "        X_train_fold, X_val_fold = X_train.iloc[train_idx], X_train.iloc[val_idx]\n",
    "        y_train_fold, y_val_fold = y_train[train_idx], y_train[val_idx]\n",
    "        \n",
    "        pipeline = Pipeline([\n",
    "            ('preprocessor', preprocessor),\n",
    "            ('classifier', model)\n",
    "        ])\n",
    "        \n",
    "        pipeline.fit(X_train_fold, y_train_fold)\n",
    "        y_pred = pipeline.predict(X_val_fold)\n",
    "        y_prob = pipeline.predict_proba(X_val_fold)[:, 1] if hasattr(model, 'predict_proba') else None\n",
    "        \n",
    "        f1_scores.append(f1_score(y_val_fold, y_pred))\n",
    "        precision_scores.append(precision_score(y_val_fold, y_pred))\n",
    "        recall_scores.append(recall_score(y_val_fold, y_pred))\n",
    "        roc_auc_scores.append(roc_auc_score(y_val_fold, y_prob))\n",
    "    \n",
    "    return np.mean([np.mean(f1_scores), np.mean(precision_scores), np.mean(recall_scores), np.mean(roc_auc_scores)])\n",
    "\n",
    "# Define Optuna objective functions for each model\n",
    "def objective_xgb(trial):\n",
    "    params = {\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 100, 500, step=50),\n",
    "        'max_depth': trial.suggest_int('max_depth', 3, 12),\n",
    "        'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
    "        'subsample': trial.suggest_float('subsample', 0.6, 1.0),\n",
    "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.6, 1.0),\n",
    "        'gamma': trial.suggest_float('gamma', 0, 10),\n",
    "        'reg_alpha': trial.suggest_float('reg_alpha', 0, 10),\n",
    "        'reg_lambda': trial.suggest_float('reg_lambda', 0, 10),\n",
    "        'random_state': 42,\n",
    "       # 'use_label_encoder': False,\n",
    "        'eval_metric': 'auc'\n",
    "    }\n",
    "    return cross_validate_model(xgb.XGBClassifier(**params))\n",
    "\n",
    "\n",
    "def objective_gb(trial):\n",
    "    params = {\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 100, 500, step=50),\n",
    "        'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
    "        'max_depth': trial.suggest_int('max_depth', 3, 12),\n",
    "        'subsample': trial.suggest_float('subsample', 0.6, 1.0),\n",
    "        'random_state': 42\n",
    "    }\n",
    "    return cross_validate_model(GradientBoostingClassifier(**params))\n",
    "\n",
    "\n",
    "\n",
    "# Run Optuna for each model\n",
    "study_xgb = optuna.create_study(direction='maximize')\n",
    "study_xgb.optimize(objective_xgb, n_trials=50, timeout=1800)\n",
    "\n",
    "study_gb = optuna.create_study(direction='maximize')\n",
    "study_gb.optimize(objective_gb, n_trials=50, timeout=1800)\n",
    "\n",
    "# Train best models\n",
    "best_gb = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', GradientBoostingClassifier(**study_gb.best_params, random_state=42))\n",
    "])\n",
    "best_gb.fit(X_train, y_train)\n",
    "\n",
    "best_xgb = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', xgb.XGBClassifier(**study_xgb.best_params, random_state=42, eval_metric='auc'))\n",
    "])\n",
    "best_xgb.fit(X_train, y_train)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get the best parameters for each model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params:\n",
      "\tn_estimators: 400\n",
      "\tlearning_rate: 0.15530861323399475\n",
      "\tmax_depth: 3\n",
      "\tsubsample: 0.7886683462621279\n"
     ]
    }
   ],
   "source": [
    "print(\"Gradient Boost Best params:\")\n",
    "for key, value in study_gb.best_params.items():\n",
    "    print(f\"\\t{key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost Best params:\n",
      "\tn_estimators: 300\n",
      "\tmax_depth: 6\n",
      "\tlearning_rate: 0.035264388109062864\n",
      "\tsubsample: 0.8330933949030837\n",
      "\tcolsample_bytree: 0.9979899230209462\n",
      "\tgamma: 0.01554216754804006\n",
      "\treg_alpha: 0.06777571507812014\n",
      "\treg_lambda: 4.312297528538607\n"
     ]
    }
   ],
   "source": [
    "print(\"XGBoost Best params:\")\n",
    "for key, value in study_xgb.best_params.items():\n",
    "    print(f\"\\t{key}: {value}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate model on the Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               Model  Precision  Recall  F1-Score  ROC AUC\n",
      "0            XGBoost     0.9719  0.9837    0.9778   0.9990\n",
      "1  Gradient Boosting     0.9918  0.9837    0.9878   0.9988\n"
     ]
    }
   ],
   "source": [
    "# Evaluate on test set\n",
    "def evaluate_model(model, name):\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_prob = model.predict_proba(X_test)[:, 1] if hasattr(model, 'predict_proba') else None\n",
    "    return {\n",
    "        'Model': name,\n",
    "        'Precision': round(precision_score(y_test, y_pred), 4),\n",
    "        'Recall': round(recall_score(y_test, y_pred), 4),\n",
    "        'F1-Score': round(f1_score(y_test, y_pred), 4),\n",
    "        'ROC AUC': round(roc_auc_score(y_test, y_prob) , 4) if y_prob is not None else 'N/A'\n",
    "    }\n",
    "\n",
    "results = [\n",
    "    evaluate_model(best_xgb, 'XGBoost'),\n",
    "    evaluate_model(best_gb, 'Gradient Boosting')\n",
    "]\n",
    "\n",
    "import pandas as pd\n",
    "results_df = pd.DataFrame(results).sort_values(by=[])\n",
    "print(results_df)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "machineind",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
