# Select top 3 models
final_models = {
    "XGBoost": xgb.XGBClassifier( eval_metric="auc", random_state=42),
    "Random Forest": RandomForestClassifier(n_estimators=100, random_state=42),
    "Gradient Boosting": GradientBoostingClassifier(n_estimators=100, random_state=42)
}

# Store test set evaluation results
test_results = []

for name, model in final_models.items():
    # Create a pipeline
    pipeline = Pipeline([
        ('preprocessor', preprocessor),
        ('classifier', model)
    ])

    # Train on full train + validation set
    pipeline.fit(X_train_val, y_train_val)

    # Make predictions on the test set
    y_test_pred = pipeline.predict(X_test)
    y_test_prob = pipeline.predict_proba(X_test)[:, 1] if hasattr(model, 'predict_proba') else None

    # Evaluate model
    test_precision = precision_score(y_test, y_test_pred)
    test_recall = recall_score(y_test, y_test_pred)
    test_f1 = f1_score(y_test, y_test_pred)
    test_roc_auc = roc_auc_score(y_test, y_test_prob) if y_test_prob is not None else 'N/A'

    # Store results
    test_results.append({
        "Model": name,
        "Precision": round(test_precision, 4),
        "Recall": round(test_recall, 4),
        "F1-Score": round(test_f1, 4),
        "ROC AUC": round(test_roc_auc, 4) if test_roc_auc != "N/A" else "N/A"
    })
    

test_results_df = pd.DataFrame(test_results)
test_results_df.sort_values(by = ['ROC AUC', 'F1-Score'], ascending= False).reset_index(drop = True)